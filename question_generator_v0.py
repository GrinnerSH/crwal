import json
import requests
import random
import os
import time
from datetime import datetime
from config import config
from graph_module.fact_extractor import LLMExtractor

class QuestionGenerator:
    def __init__(self):
        self.llm_extractor = LLMExtractor()

    def _batch_llm_call(self, prompt, max_retries=2):
        """
        æ‰¹é‡è°ƒç”¨LLMï¼Œæ”¯æŒä¸åŒçš„APIå“åº”æ ¼å¼ï¼Œå¸¦é‡è¯•æœºåˆ¶
        """
        for retry in range(max_retries + 1):
            try:
                payload = {
                    "model": config.LLM_MODEL_NAME,
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": 0.8,
                    "max_tokens": min(config.LLM_MAX_TOKENS, 4000)
                }
                headers = {'Authorization': f'Bearer {config.LLM_API_KEY}', 'Content-Type': 'application/json'}
                
                # æ ¹æ®prompté•¿åº¦è°ƒæ•´è¶…æ—¶æ—¶é—´
                prompt_length = len(prompt)
                if prompt_length > 10000:
                    timeout = 60
                elif prompt_length > 5000:
                    timeout = 45
                else:
                    timeout = 30
                
                response = requests.post(config.LLM_API_BASE_URL, headers=headers, data=json.dumps(payload), timeout=timeout)
                
                if response.status_code != 200:
                    error_msg = f"APIè°ƒç”¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
                    print(f"  {error_msg}")
                    if retry < max_retries:
                        print(f"  é‡è¯• {retry + 1}/{max_retries}...")
                        continue
                    return f"APIè°ƒç”¨å¤±è´¥ï¼šHTTP {response.status_code}"
                
                response_data = response.json()
                
                # å°è¯•ä¸åŒçš„å“åº”æ ¼å¼
                if 'choices' in response_data and len(response_data['choices']) > 0:
                    if 'message' in response_data['choices'][0]:
                        content = response_data['choices'][0]['message']['content']
                        if content:
                            return content.strip()
                    elif 'text' in response_data['choices'][0]:
                        content = response_data['choices'][0]['text']
                        if content:
                            return content.strip()
                elif 'data' in response_data:
                    return str(response_data['data']).strip()
                elif 'content' in response_data:
                    return str(response_data['content']).strip()
                
                error_msg = f"æœªçŸ¥çš„APIå“åº”æ ¼å¼: {response_data}"
                print(f"  {error_msg}")
                if retry < max_retries:
                    print(f"  é‡è¯• {retry + 1}/{max_retries}...")
                    continue
                return "APIè°ƒç”¨å¤±è´¥ï¼šæœªçŸ¥å“åº”æ ¼å¼"
                    
            except requests.exceptions.Timeout:
                error_msg = "APIè°ƒç”¨è¶…æ—¶"
                print(f"  {error_msg}")
                if retry < max_retries:
                    print(f"  é‡è¯• {retry + 1}/{max_retries}...")
                    continue
                return "APIè°ƒç”¨å¤±è´¥ï¼šè¯·æ±‚è¶…æ—¶"
            except requests.exceptions.RequestException as e:
                error_msg = f"ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {e}"
                print(f"  {error_msg}")
                if retry < max_retries:
                    print(f"  é‡è¯• {retry + 1}/{max_retries}...")
                    continue
                return f"APIè°ƒç”¨å¤±è´¥ï¼šç½‘ç»œé”™è¯¯ - {str(e)}"
            except json.JSONDecodeError as e:
                error_msg = f"JSONè§£æå¼‚å¸¸: {e}"
                print(f"  {error_msg}")
                if retry < max_retries:
                    print(f"  é‡è¯• {retry + 1}/{max_retries}...")
                    continue
                return "APIè°ƒç”¨å¤±è´¥ï¼šå“åº”æ ¼å¼é”™è¯¯"
            except Exception as e:
                error_msg = f"LLM APIè°ƒç”¨å¤±è´¥: {e}"
                print(f"  {error_msg}")
                if retry < max_retries:
                    print(f"  é‡è¯• {retry + 1}/{max_retries}...")
                    continue
                return f"APIè°ƒç”¨å¼‚å¸¸: {str(e)}"
                
        return "APIè°ƒç”¨å¤±è´¥ï¼šé‡è¯•æ¬¡æ•°è€—å°½"

    def _parse_llm_response(self, response_str, expected_count, prefix="å¥å­", separator=None):
        """
        è§£æLLMè¿”å›çš„å¸¦ç¼–å·çš„å“åº”å­—ç¬¦ä¸² - æ”¹è¿›ç‰ˆæœ¬æ”¯æŒå¤šç§æ ¼å¼å’Œè‡ªå®šä¹‰åˆ†éš”ç¬¦ã€‚
        """
        results = []
        try:
            if not response_str or response_str.startswith("APIè°ƒç”¨å¤±è´¥"):
                print(f"    âš ï¸  LLMå“åº”æ— æ•ˆï¼Œè¿”å›ç©ºç»“æœ")
                return results
            
            # æ¸…ç†å“åº”å†…å®¹
            response_str = response_str.strip()
            
            # å°è¯•å¤šç§è§£ææ¨¡å¼
            patterns_to_try = [
                # æ¨¡å¼1: "ç¼–å·: å†…å®¹" æ ¼å¼ (å¦‚ "æè¿° 1: xxx", "é™ˆè¿° 2: yyy")
                (rf'{prefix}\s*(\d+)\s*[:ï¼š]\s*(.+)', 2),
                # æ¨¡å¼2: çº¯ç¼–å·æ ¼å¼ (å¦‚ "1. xxx", "2. yyy")
                (r'(\d+)[\.\)]\s*(.+)', 2),
                # æ¨¡å¼3: è‡ªå®šä¹‰åˆ†éš”ç¬¦æ ¼å¼
                (rf'(.+?){separator}(.+)' if separator else None, 2),
                # æ¨¡å¼4: æŒ‰è¡Œåˆ†å‰²ï¼Œä¸è€ƒè™‘ç¼–å·
                (r'(.+)', 1)
            ]
            
            lines = response_str.split('\n')
            
            for pattern, group_count in patterns_to_try:
                if pattern is None:
                    continue
                    
                import re
                temp_results = []
                
                for line in lines:
                    line = line.strip()
                    if not line:
                        continue
                        
                    match = re.search(pattern, line)
                    if match:
                        if group_count == 2:
                            content = match.group(2).strip()
                        else:
                            content = match.group(1).strip()
                        
                        if content and len(content) > 5:  # è¿‡æ»¤å¤ªçŸ­çš„å†…å®¹
                            temp_results.append(content)
                
                # å¦‚æœè¿™ç§æ¨¡å¼æ‰¾åˆ°äº†ç»“æœï¼Œä½¿ç”¨å®ƒ
                if temp_results:
                    results = temp_results
                    break
            
            # å¦‚æœä»ç„¶æ²¡æœ‰ç»“æœï¼Œå°è¯•ç®€å•æŒ‰è¡Œåˆ†å‰²
            if not results:
                for line in lines:
                    line = line.strip()
                    if line and len(line) > 10:
                        results.append(line)
            
            # é™åˆ¶ç»“æœæ•°é‡
            if expected_count > 0:
                results = results[:expected_count]
            
            print(f"    âœ… æˆåŠŸè§£æ {len(results)}/{expected_count} ä¸ª{prefix}")
            return results

        except Exception as e:
            print(f"    âŒ è§£æLLMå“åº”æ—¶å‡ºé”™: {e}")
            return results

    def generate_questions(self, graph, num_questions=50, strategy='combined', long_path_ratio=0.5, batch_size=10):
        """
        æ•´åˆçš„é—®é¢˜ç”Ÿæˆä¸»å…¥å£ - æ”¯æŒé“¾å¼æ¨ç†å’Œå®ä½“ä¸­å¿ƒä¸¤ç§ç­–ç•¥
        
        Args:
            graph: çŸ¥è¯†å›¾è°±å¯¹è±¡
            num_questions: è¦ç”Ÿæˆçš„é—®é¢˜æ€»æ•°
            strategy: 'entity_centric', 'chain_of_thought', æˆ– 'combined'
            long_path_ratio: åœ¨ 'combined' ç­–ç•¥ä¸‹ï¼Œé•¿è·¯å¾„é—®é¢˜çš„æ¯”ä¾‹
            batch_size: æ‰¹æ¬¡å¤§å°
            
        Returns:
            dict: åŒ…å«ç”Ÿæˆç»“æœçš„å®Œæ•´æŠ¥å‘Š
        """
        print(f"\n" + "ğŸ”¥"*25 + " æ•´åˆé—®é¢˜ç”Ÿæˆç­–ç•¥ " + "ğŸ”¥"*25)
        print(f"ğŸ“‹ å‚æ•°é…ç½®:")
        print(f"   â€¢ ç›®æ ‡é—®é¢˜æ•°é‡: {num_questions}")
        print(f"   â€¢ ç”Ÿæˆç­–ç•¥: {strategy}")
        print(f"   â€¢ é•¿è·¯å¾„æ¯”ä¾‹: {long_path_ratio}")
        print(f"   â€¢ æ‰¹æ¬¡å¤§å°: {batch_size}")
        print(f"" + "="*80)
        
        try:
            # è®¡ç®—ä¸¤ç§ç±»å‹é—®é¢˜çš„æ•°é‡
            num_long_path = 0
            if strategy in ['chain_of_thought', 'combined']:
                num_long_path = int(num_questions * long_path_ratio) if strategy == 'combined' else num_questions

            num_entity_centric = num_questions - num_long_path
            
            print(f"ğŸ“Š é—®é¢˜åˆ†é…:")
            print(f"   â€¢ é“¾å¼æ¨ç†é—®é¢˜: {num_long_path} ä¸ª")
            print(f"   â€¢ å®ä½“ä¸­å¿ƒé—®é¢˜: {num_entity_centric} ä¸ª")
            
            all_samples = []
            
            # 1. ç”Ÿæˆé“¾å¼æ¨ç†é—®é¢˜ (åŸºäºé•¿è·¯å¾„)
            if num_long_path > 0:
                print(f"\nğŸ”— å¼€å§‹ç”Ÿæˆé“¾å¼æ¨ç†é—®é¢˜...")
                chain_samples = self._generate_chain_of_thought_questions(graph, num_long_path, batch_size)
                all_samples.extend(chain_samples)
                print(f"âœ… é“¾å¼æ¨ç†é—®é¢˜ç”Ÿæˆå®Œæˆ: {len(chain_samples)} ä¸ª")

            # 2. ç”Ÿæˆå®ä½“ä¸­å¿ƒé—®é¢˜ (å¤ç”¨ç°æœ‰é€»è¾‘)
            if num_entity_centric > 0:
                print(f"\nğŸ¢ å¼€å§‹ç”Ÿæˆå®ä½“ä¸­å¿ƒé—®é¢˜...")
                entity_samples = self._generate_entity_centric_questions(graph, num_entity_centric, batch_size)
                all_samples.extend(entity_samples)
                print(f"âœ… å®ä½“ä¸­å¿ƒé—®é¢˜ç”Ÿæˆå®Œæˆ: {len(entity_samples)} ä¸ª")

            # 3. ç”Ÿæˆæœ€ç»ˆæ•°æ®é›†
            print(f"\nğŸ“Š ç”Ÿæˆç»¼åˆæ•°æ®é›†...")
            final_result = self._create_integrated_dataset(all_samples)
            
            print(f"\nğŸ‰ æ•´åˆé—®é¢˜ç”Ÿæˆå®Œæˆ!")
            print(f"   â€¢ æ€»æ ·æœ¬æ•°: {len(all_samples)}")
            print(f"   â€¢ éªŒè¯é€šè¿‡æ•°: {final_result.get('validated_count', 0)}")
            print(f"   â€¢ éªŒè¯é€šè¿‡ç‡: {final_result.get('validation_rate', 0):.1f}%")
            
            return final_result
            
        except Exception as e:
            error_result = {
                'success': False,
                'error': str(e),
                'total_samples': 0,
                'validated_count': 0,
                'validation_rate': 0
            }
            print(f"\nâŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            return error_result

    def _generate_chain_of_thought_questions(self, graph, num_questions, batch_size):
        """
        ç”ŸæˆåŸºäºé•¿è·¯å¾„çš„é“¾å¼æ¨ç†é—®é¢˜
        
        Args:
            graph: çŸ¥è¯†å›¾è°±å¯¹è±¡
            num_questions: è¦ç”Ÿæˆçš„é—®é¢˜æ•°é‡
            batch_size: æ‰¹æ¬¡å¤§å°
            
        Returns:
            list: ç”Ÿæˆçš„é“¾å¼æ¨ç†é—®é¢˜æ ·æœ¬åˆ—è¡¨
        """
        print(f"ğŸ”— å¼€å§‹é“¾å¼æ¨ç†é—®é¢˜ç”Ÿæˆï¼Œç›®æ ‡æ•°é‡: {num_questions}")
        
        # è·å–å›¾ä¸­çš„æ‰€æœ‰èŠ‚ç‚¹
        all_nodes = list(graph.nodes())
        if len(all_nodes) < 10:
            print(f"âŒ å›¾èŠ‚ç‚¹æ•°é‡è¿‡å°‘ ({len(all_nodes)})ï¼Œæ— æ³•ç”Ÿæˆé“¾å¼æ¨ç†é—®é¢˜")
            return []
        
        # ç¼“å­˜å›¾ç»“æ„
        self._cache_graph_structure(graph)
        
        chain_samples = []
        attempts = 0
        max_attempts = num_questions * 15  # å…è®¸æ›´å¤šå°è¯•æ¬¡æ•°ï¼Œå› ä¸ºé•¿è·¯å¾„è¾ƒéš¾æ‰¾åˆ°
        
        print(f"å›¾ä¸­å…±æœ‰ {len(all_nodes)} ä¸ªèŠ‚ç‚¹ï¼Œå¼€å§‹æœç´¢é•¿è·¯å¾„...")
        
        while len(chain_samples) < num_questions and attempts < max_attempts:
            attempts += 1
            
            # 1. éšæœºé€‰æ‹©èµ·å§‹èŠ‚ç‚¹
            start_node = random.choice(all_nodes)
            
            # 2. å¯»æ‰¾ä»è¯¥èŠ‚ç‚¹å‡ºå‘çš„é•¿è·¯å¾„
            long_paths = self._find_long_paths(start_node, min_length=4, max_paths=3, timeout=10)
            
            if not long_paths:
                continue
            
            # 3. ä¸ºæ¯æ¡é•¿è·¯å¾„ç”Ÿæˆé—®é¢˜
            for path in long_paths:
                if len(chain_samples) >= num_questions:
                    break
                    
                question_sample = self._create_chain_question_sample(path, graph)
                if question_sample:
                    chain_samples.append(question_sample)
                    
            if len(chain_samples) % 10 == 0 and len(chain_samples) > 0:
                print(f"  å·²ç”Ÿæˆ {len(chain_samples)}/{num_questions} ä¸ªé“¾å¼æ¨ç†é—®é¢˜")
        
        print(f"é“¾å¼æ¨ç†é—®é¢˜ç”Ÿæˆå®Œæˆï¼šæˆåŠŸç”Ÿæˆ {len(chain_samples)} ä¸ªæ ·æœ¬ (å°è¯• {attempts} æ¬¡)")
        
        # åˆ†æ‰¹å¤„ç†é“¾å¼æ¨ç†é—®é¢˜çš„åç»­æ­¥éª¤
        if chain_samples:
            self._process_chain_samples_in_batches(chain_samples, batch_size)
        
        return chain_samples

    def _find_long_paths(self, start_node, min_length=4, max_paths=5, timeout=10):
        """
        å¯»æ‰¾ä»æŸä¸ªå®ä½“å‡ºå‘ï¼Œè·¯å¾„é•¿åº¦å¤§äºç­‰äºmin_lengthçš„é•¿è·¯å¾„ã€‚
        é‡‡ç”¨"å¸¦æ·±åº¦é™åˆ¶çš„éšæœºæ¸¸èµ°"ç­–ç•¥é¿å…è·¯å¾„çˆ†ç‚¸å’Œæ€§èƒ½é—®é¢˜ã€‚

        Args:
            start_node: èµ·å§‹å®ä½“
            min_length: è·¯å¾„çš„æœ€å°é•¿åº¦ (èŠ‚ç‚¹æ•°é‡ï¼Œæ‰€ä»¥éœ€è¦å¤§äº3æ‰èƒ½æœ‰3è·³)
            max_paths: æœ€å¤šå¯»æ‰¾å¤šå°‘æ¡è·¯å¾„
            timeout: æœç´¢è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
            
        Returns:
            list: åŒ…å«å¤šæ¡é•¿è·¯å¾„çš„åˆ—è¡¨ï¼Œæ¯æ¡è·¯å¾„æ ¼å¼ä¸º [node1, node2, node3, ...]
        """
        all_paths = []
        start_time = time.time()
        attempts = 0
        max_attempts = max_paths * 20  # é™åˆ¶å°è¯•æ¬¡æ•°
        
        while len(all_paths) < max_paths and time.time() - start_time < timeout and attempts < max_attempts:
            attempts += 1
            path = self._perform_random_walk(start_node, min_length)
            
            if path and len(path) >= min_length:
                # æ£€æŸ¥è·¯å¾„æ˜¯å¦ä¸å·²æœ‰è·¯å¾„è¶³å¤Ÿä¸åŒ
                if self._is_path_unique(path, all_paths):
                    all_paths.append(path)
        
        return all_paths

    def _perform_random_walk(self, start_node, min_length, max_length=8):
        """
        ä»æŒ‡å®šèŠ‚ç‚¹å¼€å§‹æ‰§è¡Œéšæœºæ¸¸èµ°ï¼Œç”Ÿæˆé•¿è·¯å¾„
        
        Args:
            start_node: èµ·å§‹èŠ‚ç‚¹
            min_length: æœ€å°è·¯å¾„é•¿åº¦
            max_length: æœ€å¤§è·¯å¾„é•¿åº¦
            
        Returns:
            list: ç”Ÿæˆçš„è·¯å¾„èŠ‚ç‚¹åˆ—è¡¨
        """
        path = [start_node]
        current_node = start_node
        visited_recently = set([start_node])  # é˜²æ­¢çŸ­æœŸå†…å›å¤´
        
        for step in range(max_length - 1):
            # è·å–å½“å‰èŠ‚ç‚¹çš„é‚»å±…
            neighbors = self.graph_cache.get(current_node, [])
            
            # è¿‡æ»¤æ‰æœ€è¿‘è®¿é—®çš„èŠ‚ç‚¹
            available_neighbors = [n for n in neighbors if n not in visited_recently]
            
            if not available_neighbors:
                # å¦‚æœæ²¡æœ‰å¯ç”¨é‚»å±…ï¼Œè¯•è¯•åŒ…å«æœ€è¿‘è®¿é—®çš„èŠ‚ç‚¹
                available_neighbors = [n for n in neighbors if n not in path[-2:]] if len(path) >= 2 else neighbors
            
            if not available_neighbors:
                break
            
            # éšæœºé€‰æ‹©ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
            next_node = random.choice(available_neighbors)
            path.append(next_node)
            current_node = next_node
            
            # æ›´æ–°æœ€è¿‘è®¿é—®è®°å½•
            visited_recently.add(next_node)
            if len(visited_recently) > 3:  # åªä¿ç•™æœ€è¿‘3ä¸ªèŠ‚ç‚¹çš„è®°å½•
                visited_recently.pop()
        
        return path if len(path) >= min_length else None

    def _is_path_unique(self, new_path, existing_paths, similarity_threshold=0.7):
        """
        æ£€æŸ¥æ–°è·¯å¾„æ˜¯å¦ä¸å·²æœ‰è·¯å¾„è¶³å¤Ÿä¸åŒ
        
        Args:
            new_path: æ–°ç”Ÿæˆçš„è·¯å¾„
            existing_paths: å·²æœ‰çš„è·¯å¾„åˆ—è¡¨
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            
        Returns:
            bool: å¦‚æœè·¯å¾„è¶³å¤Ÿç‹¬ç‰¹è¿”å›True
        """
        if not existing_paths:
            return True
        
        new_path_set = set(new_path)
        
        for existing_path in existing_paths:
            existing_path_set = set(existing_path)
            
            # è®¡ç®—èŠ‚ç‚¹é‡å åº¦
            intersection = new_path_set.intersection(existing_path_set)
            union = new_path_set.union(existing_path_set)
            
            if len(union) == 0:
                continue
                
            similarity = len(intersection) / len(union)
            
            if similarity > similarity_threshold:
                return False
        
        return True

    def _create_chain_question_sample(self, path, graph):
        """
        æ ¹æ®é•¿è·¯å¾„åˆ›å»ºé“¾å¼æ¨ç†é—®é¢˜æ ·æœ¬
        
        Args:
            path: é•¿è·¯å¾„èŠ‚ç‚¹åˆ—è¡¨
            graph: çŸ¥è¯†å›¾è°±å¯¹è±¡
            
        Returns:
            dict: é—®é¢˜æ ·æœ¬
        """
        if len(path) < 4:
            return None
        
        # ç”Ÿæˆé—®é¢˜å’Œç­”æ¡ˆ
        question = self._generate_question_from_long_path(path)
        
        if not question:
            return None
        
        # æ„å»ºæ ·æœ¬
        sample_id = f"chain_{hash(tuple(path))}_{len(path)}"
        
        sample = {
            'sample_id': sample_id,
            'strategy': 'chain_of_thought',
            'question_type': 'multi_hop_reasoning',
            'path': path,
            'path_length': len(path),
            'start_entity': path[0],
            'end_entity': path[-1],
            'question': question,
            'answer': path[-1],  # ç­”æ¡ˆæ˜¯è·¯å¾„çš„ç»ˆç‚¹
            'intermediate_entities': path[1:-1],
            'reasoning_steps': self._extract_reasoning_steps(path, graph),
            'generation_timestamp': datetime.now().isoformat(),
            'status': 'generated'
        }
        
        return sample

    def _generate_question_from_long_path(self, path):
        """
        æ ¹æ®ä¸€æ¡é•¿è·¯å¾„ï¼Œç”Ÿæˆä¸€ä¸ªéœ€è¦é“¾å¼æ¨ç†çš„é—®é¢˜ï¼ˆå¸¦èƒŒæ™¯æ•…äº‹ï¼‰ã€‚

        Args:
            path: ä¸€æ¡é•¿è·¯å¾„ï¼Œæ ¼å¼ä¸º [node1, node2, node3, ...]
            
        Returns:
            str: ç”Ÿæˆçš„å®Œæ•´é—®é¢˜å­—ç¬¦ä¸²ï¼ˆåŒ…å«èƒŒæ™¯å’Œé—®é¢˜ï¼‰
        """
        if len(path) < 4:
            return None
        
        start_entity = path[0]
        end_entity = path[-1]
        intermediate_entities = path[1:-1]
        
        # ä¸ºé“¾å¼è·¯å¾„ç”ŸæˆèƒŒæ™¯æ•…äº‹
        background_story = self._generate_chain_background_story(path)
        
        # ç”Ÿæˆä¸èƒŒæ™¯æ•…äº‹è¡”æ¥çš„é—®é¢˜
        question_part = self._generate_chain_question_part(start_entity, intermediate_entities)
        
        # ç»„åˆå®Œæ•´é—®é¢˜ï¼ˆå‚è€ƒç›®æ ‡æ ¼å¼ï¼‰
        full_question = f"**é—®é¢˜ï¼š**  \n{background_story}{question_part}  \n\n**è§£æï¼š**  \n1. æ ¹æ®è·¯å¾„å…³ç³»ï¼Œ{start_entity}é€šè¿‡{len(intermediate_entities)}æ­¥å…³è”ã€‚  \n2. å…³é”®ä¸­é—´å®ä½“åŒ…æ‹¬{intermediate_entities[0] if intermediate_entities else 'ç›¸å…³å®ä½“'}ç­‰ã€‚  \n3. éœ€è¦æ•´åˆè·¯å¾„ä¸­çš„æ‰€æœ‰å…³ç³»ä¿¡æ¯æ¥æ¨ç†æœ€ç»ˆç­”æ¡ˆã€‚"
        
        return full_question

    def _generate_chain_background_story(self, path):
        """
        ä¸ºé“¾å¼è·¯å¾„ç”ŸæˆèƒŒæ™¯æ•…äº‹
        """
        start_entity = path[0]
        end_entity = path[-1]
        intermediate_entities = path[1:-1]
        
        # è°ƒç”¨LLMç”ŸæˆèƒŒæ™¯æ•…äº‹
        prompt = f"""ä½ æ˜¯ä¸€ä½é—®é¢˜ç¼–ç»‡ä¸“å®¶ã€‚è¯·æ ¹æ®ä¸‹é¢çš„å®ä½“è·¯å¾„ï¼Œåˆ›å»ºä¸€ä¸ªé—®é¢˜èƒŒæ™¯æ•…äº‹ï¼Œæ­£å¸¸å™è¿°ï¼Œé¿å…è¿‡äºæ–‡å­¦åŒ–ã€‚

è¦æ±‚ï¼š
1. **å®ä½“æ³›åŒ–**ï¼šå°†å…·ä½“çš„å®ä½“åç§°æ›¿æ¢ä¸ºæ›´é€šç”¨çš„æè¿°ï¼ˆä¾‹å¦‚ï¼Œ"å¼ ä¸‰" -> "ä¸€ä½ä½œå®¶"ï¼›"åŒ—äº¬å¤§å­¦" -> "ä¸€æ‰€çŸ¥åå­¦åºœ"ï¼‰
2. **å…³ç³»éšè—**ï¼šä¸è¦è¿‡äºç›´æ¥åœ°è¯´æ˜å®ä½“é—´çš„å…³ç³»ï¼Œå¯ä»¥é€šè¿‡æ›´æ¢è¡¨è¿°ç­‰æ–¹å¼è¡¨è¾¾ï¼Œä½†æ˜¯éœ€è¦ç¡®ä¿é€»è¾‘æ¸…æ™°ä»¥åŠå…³ç³»æ­£ç¡®
3. **ç¦æ­¢æ³„éœ²ç­”æ¡ˆ**ï¼šç»å¯¹ä¸èƒ½åœ¨é—®é¢˜èƒŒæ™¯æ•…äº‹ä¸­å‡ºç°æœ€ç»ˆç­”æ¡ˆå®ä½“ï¼š{end_entity}
4. **ä¿æŒé€»è¾‘**ï¼šé—®é¢˜èƒŒæ™¯æ•…äº‹å¿…é¡»ä¿ç•™è·¯å¾„ä¸­çš„æ ¸å¿ƒé€»è¾‘å…³ç³»ï¼Œç¡®ä¿å¯ä»¥æ¨ç†å‡ºç­”æ¡ˆ

å®ä½“è·¯å¾„ï¼š{' -> '.join(path)}
æœ€ç»ˆç­”æ¡ˆï¼ˆä¸å¯åœ¨æ•…äº‹ä¸­å‡ºç°ï¼‰ï¼š{end_entity}

è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´çš„èƒŒæ™¯æ•…äº‹ï¼ˆ100å­—ä»¥å†…ï¼‰ï¼š"""

        result = self._batch_llm_call(prompt)
        
        if result and not result.startswith("APIè°ƒç”¨å¤±è´¥"):
            return result.strip()
        else:
            # å›é€€ï¼šç”Ÿæˆç®€å•çš„èƒŒæ™¯æ•…äº‹
            return f"åœ¨æŸä¸ªç ”ç©¶é¢†åŸŸï¼Œä¸€ä¸ªé‡è¦çš„èµ·ç‚¹ä¸å¤šä¸ªç›¸å…³æ¦‚å¿µå­˜åœ¨è¿æ¥ã€‚è¿™äº›æ¦‚å¿µä¹‹é—´å½¢æˆäº†ä¸€ä¸ªå¤æ‚çš„å…³è”ç½‘ç»œã€‚"

    def _generate_chain_question_part(self, start_entity, intermediate_entities):
        """
        ç”Ÿæˆé“¾å¼æ¨ç†é—®é¢˜çš„æé—®éƒ¨åˆ†
        """
        # å¯¹èµ·å§‹å®ä½“è¿›è¡Œæ³›åŒ–
        generalized_start = self._generalize_entity(start_entity)
        
        templates = [
            f"è¿™ä¸ªç½‘ç»œæœ€ç»ˆæŒ‡å‘çš„æ ¸å¿ƒæ¦‚å¿µæ˜¯ä»€ä¹ˆï¼Ÿ",
            f"é€šè¿‡è¿™äº›å…³è”ï¼Œæœ€ç»ˆä¼šåˆ°è¾¾å“ªä¸ªç›®æ ‡ï¼Ÿ",
            f"è¿™ä¸ªå…³è”é“¾çš„ç»ˆç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ",
            f"æ ¹æ®è¿™äº›çº¿ç´¢ï¼Œæœ€ç»ˆçš„ç­”æ¡ˆæ˜¯ä»€ä¹ˆï¼Ÿ"
        ]
        
        return random.choice(templates)

    def _generalize_entity(self, entity):
        """
        å¯¹å®ä½“è¿›è¡Œæ³›åŒ–å¤„ç†
        """
        # ç®€å•çš„å®ä½“æ³›åŒ–é€»è¾‘
        if any(char in entity for char in ['å¤§å­¦', 'å­¦é™¢', 'å­¦æ ¡']):
            return "ä¸€æ‰€æ•™è‚²æœºæ„"
        elif any(char in entity for char in ['å…¬å¸', 'é›†å›¢', 'ä¼ä¸š']):
            return "ä¸€ä¸ªç»„ç»‡"
        elif any(char in entity for char in ['ä¹¦', 'è‘—ä½œ', 'ä½œå“']):
            return "ä¸€éƒ¨ä½œå“"
        elif any(char in entity for char in ['äºº', 'å®¶', 'è€…']):
            return "ä¸€ä½äººç‰©"
        else:
            return "ä¸€ä¸ªç›¸å…³æ¦‚å¿µ"

    def _extract_reasoning_steps(self, path, graph):
        """
        ä»è·¯å¾„ä¸­æå–æ¨ç†æ­¥éª¤
        
        Args:
            path: è·¯å¾„èŠ‚ç‚¹åˆ—è¡¨
            graph: çŸ¥è¯†å›¾è°±å¯¹è±¡
            
        Returns:
            list: æ¨ç†æ­¥éª¤åˆ—è¡¨
        """
        steps = []
        
        for i in range(len(path) - 1):
            current_node = path[i]
            next_node = path[i + 1]
            
            # å°è¯•è·å–çœŸå®çš„å…³ç³»
            relation = 'ç›¸å…³äº'  # é»˜è®¤å…³ç³»
            if hasattr(graph, 'get_edge_data'):
                edge_data = graph.get_edge_data(current_node, next_node)
                if edge_data:
                    if isinstance(edge_data, dict) and edge_data:
                        relation = list(edge_data.keys())[0]
            
            step = {
                'step': i + 1,
                'from_entity': current_node,
                'relation': relation,
                'to_entity': next_node,
                'description': f"{current_node} {relation} {next_node}"
            }
            steps.append(step)
        
        return steps

    def _generate_entity_centric_questions(self, graph, num_questions, batch_size):
        """
        ç”ŸæˆåŸºäºå®ä½“ä¸­å¿ƒçš„é—®é¢˜ï¼ˆå¤ç”¨åŸæœ‰çš„å¤šæºçº¿ç´¢èšåˆé€»è¾‘ï¼‰
        
        Args:
            graph: çŸ¥è¯†å›¾è°±å¯¹è±¡
            num_questions: è¦ç”Ÿæˆçš„é—®é¢˜æ•°é‡
            batch_size: æ‰¹æ¬¡å¤§å°
            
        Returns:
            list: ç”Ÿæˆçš„å®ä½“ä¸­å¿ƒé—®é¢˜æ ·æœ¬åˆ—è¡¨
        """
        print(f"ğŸ¢ å¼€å§‹å®ä½“ä¸­å¿ƒé—®é¢˜ç”Ÿæˆï¼Œç›®æ ‡æ•°é‡: {num_questions}")
        
        # ä½¿ç”¨åŸæœ‰çš„å¤šæºçº¿ç´¢èšåˆé€»è¾‘
        entity_samples = self._multi_source_clue_aggregation(graph, num_questions)
        
        if not entity_samples:
            print("âŒ å®ä½“ä¸­å¿ƒé—®é¢˜ç”Ÿæˆå¤±è´¥")
            return []
        
        print(f"âœ… å®ä½“ä¸­å¿ƒçº¿ç´¢èšåˆå®Œæˆï¼Œç”Ÿæˆäº† {len(entity_samples)} ä¸ªç­”æ¡ˆ-çº¿ç´¢ç»„åˆ")
        
        # åˆ†æ‰¹å¤„ç†å®ä½“ä¸­å¿ƒé—®é¢˜
        if entity_samples:
            self._process_entity_samples_in_batches(entity_samples, batch_size)
        
        return entity_samples

    def _process_chain_samples_in_batches(self, chain_samples, batch_size):
        """
        åˆ†æ‰¹å¤„ç†é“¾å¼æ¨ç†é—®é¢˜æ ·æœ¬
        """
        total_batches = (len(chain_samples) + batch_size - 1) // batch_size
        print(f"\nåˆ†æ‰¹å¤„ç†é“¾å¼æ¨ç†é—®é¢˜ï¼š{len(chain_samples)} ä¸ªæ ·æœ¬åˆ†ä¸º {total_batches} æ‰¹æ¬¡")
        
        for batch_idx in range(total_batches):
            start_idx = batch_idx * batch_size
            end_idx = min(start_idx + batch_size, len(chain_samples))
            batch_samples = chain_samples[start_idx:end_idx]
            
            print(f"\n=== å¤„ç†é“¾å¼æ¨ç†æ‰¹æ¬¡ {batch_idx + 1}/{total_batches} ===")
            
            # å¯¹é“¾å¼æ¨ç†é—®é¢˜è¿›è¡ŒéªŒè¯å’Œä¼˜åŒ–
            self._validate_chain_questions_batch(batch_samples)
            self._save_stage_results(batch_samples, "chain_reasoning_validation", batch_idx + 1)

    def _process_entity_samples_in_batches(self, entity_samples, batch_size):
        """
        åˆ†æ‰¹å¤„ç†å®ä½“ä¸­å¿ƒé—®é¢˜æ ·æœ¬
        """
        total_batches = (len(entity_samples) + batch_size - 1) // batch_size
        print(f"\nåˆ†æ‰¹å¤„ç†å®ä½“ä¸­å¿ƒé—®é¢˜ï¼š{len(entity_samples)} ä¸ªæ ·æœ¬åˆ†ä¸º {total_batches} æ‰¹æ¬¡")
        
        for batch_idx in range(total_batches):
            start_idx = batch_idx * batch_size
            end_idx = min(start_idx + batch_size, len(entity_samples))
            batch_samples = entity_samples[start_idx:end_idx]
            
            print(f"\n=== å¤„ç†å®ä½“ä¸­å¿ƒæ‰¹æ¬¡ {batch_idx + 1}/{total_batches} ===")
            
            # æ·±åº¦æ¨¡ç³Šä¸æ•…äº‹ç¼–ç»‡
            self._deep_obfuscation_and_narrative_weaving_batch(batch_samples)
            self._save_stage_results(batch_samples, "entity_obfuscation", batch_idx + 1)
            
            # é—®é¢˜ç”Ÿæˆä¸æ ¡éªŒ
            self._question_generation_and_validation_batch(batch_samples)
            self._save_stage_results(batch_samples, "entity_validation", batch_idx + 1)

    def _validate_chain_questions_batch(self, batch_samples):
        """
        éªŒè¯é“¾å¼æ¨ç†é—®é¢˜çš„é€»è¾‘æ€§å’Œå¯ç­”æ€§
        """
        print(f"éªŒè¯ {len(batch_samples)} ä¸ªé“¾å¼æ¨ç†é—®é¢˜...")
        
        validated_count = 0
        for sample in batch_samples:
            # åŸºæœ¬æ£€æŸ¥
            if (sample.get('question') and 
                sample.get('answer') and 
                sample.get('path_length', 0) >= 4):
                
                # æ£€æŸ¥é—®é¢˜æ˜¯å¦åŒ…å«ç­”æ¡ˆ
                question_lower = sample['question'].lower()
                answer_lower = str(sample['answer']).lower()
                
                if answer_lower not in question_lower:
                    sample['validation_status'] = 'é€šè¿‡'
                    sample['final_status'] = 'validated'
                    validated_count += 1
                else:
                    sample['validation_status'] = 'å¤±è´¥ï¼šé—®é¢˜åŒ…å«ç­”æ¡ˆ'
                    sample['final_status'] = 'failed'
            else:
                sample['validation_status'] = 'å¤±è´¥ï¼šç¼ºå°‘å¿…è¦å­—æ®µ'
                sample['final_status'] = 'failed'
        
        print(f"é“¾å¼æ¨ç†é—®é¢˜éªŒè¯å®Œæˆï¼š{validated_count}/{len(batch_samples)} é€šè¿‡")

    def _create_integrated_dataset(self, all_samples):
        """
        åˆ›å»ºæ•´åˆçš„é—®ç­”æ•°æ®é›†
        
        Args:
            all_samples: æ‰€æœ‰ç”Ÿæˆçš„æ ·æœ¬åˆ—è¡¨
            
        Returns:
            dict: åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„ç»“æœå­—å…¸
        """
        print(f"ğŸ“Š å¼€å§‹åˆ›å»ºæ•´åˆæ•°æ®é›†...")
        
        # åˆ†åˆ«ç»Ÿè®¡ä¸¤ç§ç±»å‹çš„é—®é¢˜
        chain_samples = [s for s in all_samples if s.get('strategy') == 'chain_of_thought']
        entity_samples = [s for s in all_samples if s.get('strategy') == 'multi_source_clue_aggregation']
        
        # éªŒè¯é€šè¿‡çš„é—®é¢˜
        validated_samples = [s for s in all_samples if s.get('final_status') == 'validated']
        
        print(f"ğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
        print(f"   â€¢ é“¾å¼æ¨ç†é—®é¢˜: {len(chain_samples)} ä¸ª")
        print(f"   â€¢ å®ä½“ä¸­å¿ƒé—®é¢˜: {len(entity_samples)} ä¸ª")
        print(f"   â€¢ æ€»æ ·æœ¬æ•°: {len(all_samples)} ä¸ª")
        print(f"   â€¢ éªŒè¯é€šè¿‡æ•°: {len(validated_samples)} ä¸ª")
        
        # ç”Ÿæˆæ•°æ®é›†æ–‡ä»¶
        self._save_integrated_datasets(all_samples, validated_samples, chain_samples, entity_samples)
        
        validation_rate = len(validated_samples) / len(all_samples) * 100 if all_samples else 0
        
        result = {
            'success': True,
            'total_samples': len(all_samples),
            'chain_samples': len(chain_samples),
            'entity_samples': len(entity_samples),
            'validated_samples': validated_samples,
            'validated_count': len(validated_samples),
            'validation_rate': validation_rate,
            'simple_count': len(validated_samples)  # ç®€åŒ–æ ¼å¼é—®é¢˜æ•°ç­‰äºéªŒè¯é€šè¿‡æ•°
        }
        
        return result

    def _save_integrated_datasets(self, all_samples, validated_samples, chain_samples, entity_samples):
        """
        ä¿å­˜æ•´åˆçš„æ•°æ®é›†æ–‡ä»¶
        """
        output_dir = os.path.join(os.path.dirname(config.OUTPUT_DATASET_PATH), "output")
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. ä¿å­˜å®Œæ•´çš„æ•´åˆæ•°æ®é›†
        full_output_path = os.path.join(output_dir, "integrated_qa_dataset.jsonl")
        with open(full_output_path, 'w', encoding='utf-8') as f:
            for sample in all_samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        print(f"å®Œæ•´æ•´åˆæ•°æ®é›†å·²ä¿å­˜: {full_output_path}")
        
        # 2. ä¿å­˜éªŒè¯é€šè¿‡çš„é—®é¢˜
        validated_output_path = os.path.join(output_dir, "validated_integrated_qa.jsonl")
        with open(validated_output_path, 'w', encoding='utf-8') as f:
            for sample in validated_samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        print(f"éªŒè¯é€šè¿‡çš„é—®é¢˜å·²ä¿å­˜: {validated_output_path}")
        
        # 3. ä¿å­˜ç®€åŒ–æ ¼å¼
        simple_output_path = os.path.join(output_dir, "simple_integrated_qa.jsonl")
        with open(simple_output_path, 'w', encoding='utf-8') as f:
            for sample in validated_samples:
                simple_qa = {
                    'question': sample.get('question', sample.get('generated_question', '')),
                    'answer': sample.get('answer', sample.get('answer_entity', '')),
                    'strategy': sample.get('strategy', 'unknown'),
                    'question_type': sample.get('question_type', 'unknown')
                }
                f.write(json.dumps(simple_qa, ensure_ascii=False) + '\n')
        print(f"ç®€åŒ–æ ¼å¼é—®ç­”å·²ä¿å­˜: {simple_output_path}")
        
        # 4. ä¿å­˜ç­–ç•¥åˆ†ç±»æ•°æ®é›†
        chain_output_path = os.path.join(output_dir, "chain_reasoning_qa.jsonl")
        with open(chain_output_path, 'w', encoding='utf-8') as f:
            for sample in chain_samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        print(f"é“¾å¼æ¨ç†é—®é¢˜å·²ä¿å­˜: {chain_output_path}")
        
        entity_output_path = os.path.join(output_dir, "entity_centric_qa.jsonl")
        with open(entity_output_path, 'w', encoding='utf-8') as f:
            for sample in entity_samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        print(f"å®ä½“ä¸­å¿ƒé—®é¢˜å·²ä¿å­˜: {entity_output_path}")

    def run_new_strategy(self, graph, total_questions=50, batch_size=10):
        """
        ğŸš€ ä¾¿æ·å…¥å£ï¼šè¿è¡Œæ•´åˆçš„é—®é¢˜ç”Ÿæˆç­–ç•¥ (é“¾å¼æ¨ç† + å®ä½“ä¸­å¿ƒ = 1:1)
        
        Args:
            graph: çŸ¥è¯†å›¾è°±å¯¹è±¡
            total_questions: ç›®æ ‡ç”Ÿæˆçš„é—®é¢˜æ•°é‡ (é»˜è®¤50)
            batch_size: æ‰¹æ¬¡å¤§å° (é»˜è®¤10)
            
        Returns:
            dict: åŒ…å«ç”Ÿæˆç»“æœçš„å®Œæ•´æŠ¥å‘Š
        """
        return self.generate_questions(
            graph=graph, 
            num_questions=total_questions, 
            strategy='combined', 
            long_path_ratio=0.5,  # 1:1 æ¯”ä¾‹
            batch_size=batch_size
        )

    # ç®€åŒ–çš„å¿…è¦æ”¯æŒæ–¹æ³•
    def _cache_graph_structure(self, graph):
        """
        ç¼“å­˜å›¾ç»“æ„ä»¥ä¾¿åç»­ä½¿ç”¨
        """
        if not hasattr(self, 'graph_cache'):
            self.graph_cache = {}
        
        # ç¼“å­˜æ¯ä¸ªèŠ‚ç‚¹çš„é‚»å±…ä¿¡æ¯
        for node in graph.nodes():
            self.graph_cache[node] = list(graph.successors(node))

    def _multi_source_clue_aggregation(self, graph, target_count):
        """
        ç®€åŒ–çš„å¤šæºçº¿ç´¢èšåˆæ–¹æ³•ï¼ˆä¿ç•™æ ¸å¿ƒé€»è¾‘ï¼‰
        """
        print(f"å¼€å§‹å®ä½“ä¸­å¿ƒçº¿ç´¢èšåˆï¼Œç›®æ ‡æ•°é‡ï¼š{target_count}")
        
        all_nodes = list(graph.nodes())
        if len(all_nodes) < 10:
            print(f"âŒ å›¾èŠ‚ç‚¹æ•°é‡è¿‡å°‘ ({len(all_nodes)})ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆçš„çº¿ç´¢èšåˆ")
            return []
        
        # ä¸ºäº†ä¸å›¾å¯¹è±¡äº¤äº’ï¼Œéœ€è¦ç¼“å­˜å›¾çš„é‚»æ¥ä¿¡æ¯
        self._cache_graph_structure(graph)
        
        aggregated_samples = []
        attempts = 0
        max_attempts = target_count * 10
        
        while len(aggregated_samples) < target_count and attempts < max_attempts:
            attempts += 1
            
            # éšæœºé€‰æ‹©ç›®æ ‡å®ä½“ä½œä¸ºç­”æ¡ˆ
            answer_entity = random.choice(all_nodes)
            
            # ä¸ºè¿™ä¸ªç­”æ¡ˆå®ä½“å¯»æ‰¾å¤šæ¡ç‹¬ç«‹çš„æ¨ç†è·¯å¾„
            independent_paths = self._discover_independent_clue_paths(graph, answer_entity)
            
            if len(independent_paths) < 2:
                continue
            
            # æ„å»ºçº¿ç´¢åŒ…
            clue_package = self._build_clue_package(answer_entity, independent_paths, graph)
            
            if clue_package:
                aggregated_samples.append(clue_package)
                if len(aggregated_samples) % 10 == 0:
                    print(f"  å·²èšåˆ {len(aggregated_samples)}/{target_count} ä¸ªæ ·æœ¬")
        
        print(f"å®ä½“ä¸­å¿ƒçº¿ç´¢èšåˆå®Œæˆï¼šæˆåŠŸç”Ÿæˆ {len(aggregated_samples)} ä¸ªæ ·æœ¬")
        return aggregated_samples

    def _discover_independent_clue_paths(self, graph, answer_entity, max_paths=4, max_path_length=3):
        """ç®€åŒ–çš„ç‹¬ç«‹çº¿ç´¢è·¯å¾„å‘ç°"""
        independent_paths = []
        used_entities = set([answer_entity])
        
        predecessors = list(graph.predecessors(answer_entity))
        
        if len(predecessors) < 2:
            successors = list(graph.successors(answer_entity))
            for successor in successors[:max_paths]:
                if successor not in used_entities:
                    path = [answer_entity, successor]
                    independent_paths.append(path)
                    used_entities.add(successor)
                    if len(independent_paths) >= max_paths:
                        break
            return independent_paths
        
        random.shuffle(predecessors)
        
        for pred_node in predecessors:
            if pred_node in used_entities:
                continue
                
            clue_path = [pred_node, answer_entity]
            
            if clue_path and len(clue_path) >= 2:
                path_entities = set(clue_path[:-1])
                if not path_entities.intersection(used_entities):
                    independent_paths.append(clue_path)
                    used_entities.update(path_entities)
                    
                    if len(independent_paths) >= max_paths:
                        break
        
        return independent_paths

    def _build_clue_package(self, answer_entity, independent_paths, graph=None):
        """ç®€åŒ–çš„çº¿ç´¢åŒ…æ„å»ºï¼Œå¢åŠ å…³ç³»ä¿¡æ¯æå–"""
        if not independent_paths:
            return None
        
        clue_entities = []
        clue_paths_info = []
        relation_facts = []  # æ–°å¢ï¼šå…³ç³»äº‹å®åˆ—è¡¨
        
        for i, path in enumerate(independent_paths):
            if len(path) >= 2:
                # æå–è·¯å¾„ä¸­çš„å…³ç³»ä¿¡æ¯
                path_relations = self._extract_path_relations(path, graph)
                
                clue_paths_info.append({
                    'path_id': i + 1,
                    'path_nodes': path,
                    'path_relations': path_relations,  # æ–°å¢ï¼šè·¯å¾„å…³ç³»
                    'clue_entity': path[-1] if path[-1] != answer_entity else path[-2]
                })
                
                # æ”¶é›†å…³ç³»äº‹å®
                relation_facts.extend(path_relations)
                
                if path[-1] != answer_entity:
                    clue_entities.append(path[-1])
                elif len(path) >= 2:
                    clue_entities.append(path[-2])
        
        if not clue_entities:
            return None
        
        sample_id = f"entity_clue_{hash(answer_entity)}_{len(independent_paths)}"
        
        clue_package = {
            'sample_id': sample_id,
            'strategy': 'multi_source_clue_aggregation',
            'answer_entity': answer_entity,
            'independent_paths': independent_paths,
            'clue_entities': clue_entities,
            'clue_paths_info': clue_paths_info,
            'relation_facts': relation_facts,  # æ–°å¢ï¼šå…³ç³»äº‹å®
            'num_clue_paths': len(independent_paths),
            'generation_timestamp': datetime.now().isoformat(),
            'status': 'aggregated'
        }
        
        return clue_package

    def _extract_path_relations(self, path, graph):
        """
        æå–è·¯å¾„ä¸­æ¯ä¸€æ­¥çš„å…³ç³»ä¿¡æ¯
        
        Args:
            path: èŠ‚ç‚¹è·¯å¾„åˆ—è¡¨
            graph: çŸ¥è¯†å›¾è°±å¯¹è±¡
            
        Returns:
            list: å…³ç³»äº‹å®åˆ—è¡¨ï¼Œæ ¼å¼ä¸º [{'subject': ..., 'relation': ..., 'object': ...}, ...]
        """
        relations = []
        
        if not graph or len(path) < 2:
            return relations
        
        for i in range(len(path) - 1):
            subj = path[i]
            obj = path[i + 1]
            
            # è·å–çœŸå®çš„å…³ç³»
            relation = self._get_relation_between_entities(subj, obj, graph)
            
            if relation:
                relations.append({
                    'subject': subj,
                    'relation': relation,
                    'object': obj,
                    'step': i + 1
                })
        
        return relations
    
    def _get_relation_between_entities(self, entity1, entity2, graph):
        """
        è·å–ä¸¤ä¸ªå®ä½“é—´çš„å…³ç³»
        
        Args:
            entity1: ç¬¬ä¸€ä¸ªå®ä½“
            entity2: ç¬¬äºŒä¸ªå®ä½“
            graph: çŸ¥è¯†å›¾è°±å¯¹è±¡
            
        Returns:
            str: å…³ç³»åç§°ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›é»˜è®¤å…³ç³»
        """
        if not graph or not hasattr(graph, 'get_edge_data'):
            return 'ç›¸å…³äº'
        
        # å°è¯•è·å–è¾¹æ•°æ®
        edge_data = graph.get_edge_data(entity1, entity2)
        
        if edge_data:
            if isinstance(edge_data, dict):
                if edge_data:
                    # å¯¹äºMultiDiGraphï¼Œå¯èƒ½æœ‰å¤šä¸ªå…³ç³»ï¼Œå–ç¬¬ä¸€ä¸ª
                    first_relation = list(edge_data.keys())[0]
                    if isinstance(edge_data[first_relation], dict):
                        return edge_data[first_relation].get('relation', first_relation)
                    else:
                        return first_relation
        
        # å°è¯•åå‘å…³ç³»
        edge_data = graph.get_edge_data(entity2, entity1)
        if edge_data:
            if isinstance(edge_data, dict) and edge_data:
                first_relation = list(edge_data.keys())[0]
                if isinstance(edge_data[first_relation], dict):
                    relation = edge_data[first_relation].get('relation', first_relation)
                    return f"è¢«{relation}"  # åå‘å…³ç³»
                else:
                    return f"è¢«{first_relation}"
        
        return 'ç›¸å…³äº'  # é»˜è®¤å…³ç³»

    def _deep_obfuscation_and_narrative_weaving_batch(self, batch_samples):
        """
        ç¬¬äºŒé˜¶æ®µï¼šæ·±åº¦æ¨¡ç³Šä¸æ•…äº‹ç¼–ç»‡ï¼ˆåŸºäºv4ç‰ˆæœ¬çš„é€»è¾‘ï¼‰
        
        è¿™ä¸ªé˜¶æ®µå°†ï¼š
        1. å¯¹å®ä½“è¿›è¡Œæ³›åŒ–å¤„ç†ï¼Œéšè—å…·ä½“çš„åç§°
        2. å°†ç²¾ç¡®çš„äº‹å®é™ˆè¿°è½¬åŒ–ä¸ºæ¨¡ç³Šä½†æœ‰è¶£çš„å™è¿°
        3. åˆ›å»ºç›¸å¯¹æ—¶é—´å’Œé€»è¾‘è¿æ¥
        4. ç¡®ä¿ä¸æ³„éœ²ç›®æ ‡ç­”æ¡ˆ
        """
        print(f"  å¼€å§‹æ·±åº¦æ¨¡ç³Šä¸æ•…äº‹ç¼–ç»‡...")
        
        # æ„å»ºå…³ç³»äº‹å®é™ˆè¿°
        self._build_integrated_clue_statements(batch_samples)
        
        # æ‰§è¡Œæƒ…å¢ƒæ¨¡ç³Šä¸é‡æ„
        self._process_obfuscation_and_weaving_batch(batch_samples)
        
        print(f"  æ·±åº¦æ¨¡ç³Šä¸æ•…äº‹ç¼–ç»‡å®Œæˆ")

    def _build_integrated_clue_statements(self, batch_samples):
        """
        ä¸ºæ¯ä¸ªæ ·æœ¬æ„å»ºæ•´åˆçš„çº¿ç´¢é™ˆè¿°
        """
        print(f"    æ„å»ºå…³ç³»äº‹å®é™ˆè¿°...")
        
        for sample in batch_samples:
            relation_facts = sample.get('relation_facts', [])
            answer_entity = sample.get('answer_entity', '')
            
            if not relation_facts:
                sample['integrated_clue_statement'] = "ç›¸å…³å®ä½“é—´å­˜åœ¨æŸç§å…³è”"
                continue
            
            # æ„å»ºäº‹å®é™ˆè¿°
            fact_statements = []
            for fact in relation_facts:
                statement = f"{fact['subject']} {fact['relation']} {fact['object']}"
                fact_statements.append(statement)
            
            # æ•´åˆæ‰€æœ‰äº‹å®
            integrated_statement = "ã€‚".join(fact_statements) + "ã€‚"
            sample['integrated_clue_statement'] = integrated_statement
            sample['target_entity'] = answer_entity

    def _process_obfuscation_and_weaving_batch(self, batch_samples):
        """
        æƒ…å¢ƒæ¨¡ç³Šä¸é‡æ„ - å°†ç²¾ç¡®çš„äº‹å®é™ˆè¿°è½¬åŒ–ä¸ºæ¨¡ç³Šä½†æœ‰è¶£çš„å™è¿°ï¼ˆåŸºäºv4ç‰ˆæœ¬ï¼‰
        """
        prompt = """ä½ æ˜¯ä¸€ä½é¡¶çº§çš„å‡ºé¢˜ä¸“å®¶å’Œé—®é¢˜èƒŒæ™¯æ•…äº‹ç¼–ç»‡è€…ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ä»¥ä¸‹ã€åŸå§‹äº‹å®é™ˆè¿°ã€‘è½¬åŒ–ä¸ºä¸€æ®µé€»è¾‘æ¸…æ™°çš„ã€é—®é¢˜èƒŒæ™¯æ•…äº‹ã€‘ã€‚

è½¬åŒ–è¦æ±‚ï¼š
1. **ä¿¡æ¯æ¨¡ç³ŠåŒ–**ï¼š
   - **å®ä½“æ³›åŒ–**ï¼šå°†å…·ä½“çš„äººåã€åœ°åã€ç»„ç»‡åç­‰æ›¿æ¢ä¸ºæ›´é€šç”¨çš„æè¿°ï¼ˆä¾‹å¦‚ï¼Œ"è¯—äººC" -> "ä¸€ä½è¯—äºº"ï¼›"å¹³æ±‰é“è·¯" -> "ä¸€æ¡é‡è¦çš„äº¤é€šå¹²çº¿"ï¼‰ã€‚
   - **æ•°å€¼æ¨¡ç³Š**ï¼šå°†ç²¾ç¡®çš„æ•°å­—æˆ–å¹´ä»½æ›¿æ¢ä¸ºç›¸å¯¹æˆ–æ¨¡ç³Šçš„æè¿°ï¼ˆä¾‹å¦‚ï¼Œ"36å¹³æ–¹åƒç±³" -> "è¶…è¿‡35å¹³æ–¹åƒç±³"ï¼›"1933å¹´" -> "åœ¨æŸåœºæ··æˆ˜çˆ†å‘åçš„ç¬¬ä¸‰å¹´"ï¼‰ã€‚
   - **å…³ç³»éšè—**ï¼šä¸è¦ç›´æ¥é™ˆè¿°å®ä½“é—´çš„å…³ç³»ï¼Œè€Œæ˜¯é€šè¿‡æè¿°äº‹ä»¶æ¥æš—ç¤ºå®ƒä»¬ã€‚
   **æ³¨æ„**ï¼Œåœ¨è¿™ä¸€æ­¥éª¤ä¸­ï¼Œ**ä¸å¯ä»¥å¼•å…¥ä»»ä½•é”™è¯¯ä¿¡æ¯æˆ–è™šæ„çš„äº‹å®ã€‚**

2. **æƒ…å¢ƒé‡æ„**ï¼š
   - **å»ºç«‹ç›¸å¯¹æ—¶é—´**ï¼šåˆ›é€ åŸºäºäº‹ä»¶çš„æ—¶é—´çº¿ç´¢ï¼ˆä¾‹å¦‚ï¼Œ"5å¹´å"ã€"ä¸¤å¹´ååˆæ¢å¤äº†"ï¼‰ã€‚
   - **é€»è¾‘ä¸²è”**ï¼šå°†ç¦»æ•£çš„äº‹å®æœ‰æœºåœ°ä¸²è”æˆä¸€ä¸ªè¿è´¯ã€æµç•…çš„æ•…äº‹ï¼Œè€Œä¸æ˜¯ç®€å•çš„ç½—åˆ—ã€‚
   - **ä¿æŒæ ¸å¿ƒé€»è¾‘**ï¼šæ•…äº‹å¿…é¡»ä¿ç•™åŸå§‹äº‹å®ä¸­çš„æ ¸å¿ƒå› æœå’Œæ—¶åºå…³ç³»ï¼Œç¡®ä¿é—®é¢˜æœ€ç»ˆå¯ä»¥è¢«è§£ç­”ã€‚

3. **ç¦æ­¢æ³„éœ²ç­”æ¡ˆ**ï¼š
   - åœ¨ç”Ÿæˆçš„ã€é—®é¢˜èƒŒæ™¯æ•…äº‹ã€‘ä¸­ï¼Œç»å¯¹ä¸èƒ½å‡ºç°ã€ç›®æ ‡å®ä½“ã€‘ï¼ˆå³é—®é¢˜çš„ç­”æ¡ˆï¼‰ã€‚

ç°åœ¨ï¼Œè¯·å¤„ç†ä»¥ä¸‹å†…å®¹ï¼š
"""
        
        valid_samples = []
        for i, sample in enumerate(batch_samples):
            if 'integrated_clue_statement' in sample and not sample['integrated_clue_statement'].startswith("Error"):
                prompt += f"\nåŸå§‹äº‹å®é™ˆè¿° {len(valid_samples)+1}: {sample['integrated_clue_statement']}"
                prompt += f"\nç›®æ ‡å®ä½“ {len(valid_samples)+1}: {sample.get('target_entity', '')}\n"
                valid_samples.append(sample)
        
        if not valid_samples:
            print("    æ²¡æœ‰æœ‰æ•ˆçš„äº‹å®é™ˆè¿°å¯ä¾›æ¨¡ç³ŠåŒ–å¤„ç†")
            for sample in batch_samples:
                sample['narrative_story'] = sample.get('integrated_clue_statement', 'ç›¸å…³å®ä½“é—´å­˜åœ¨æŸç§å…³è”')
            return

        prompt += "\n\nè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ï¼Œæ¯ä¸ªé—®é¢˜èƒŒæ™¯æ•…äº‹å ä¸€è¡Œ:\né—®é¢˜èƒŒæ™¯æ•…äº‹ 1: [è½¬åŒ–åçš„æ¨¡ç³ŠåŒ–æ•…äº‹]\né—®é¢˜èƒŒæ™¯æ•…äº‹ 2: [è½¬åŒ–åçš„æ¨¡ç³ŠåŒ–æ•…äº‹]\n..."
        
        results_str = self._batch_llm_call(prompt)
        if results_str and not results_str.startswith("APIè°ƒç”¨å¤±è´¥"):
            parsed_stories = self._parse_llm_response(results_str, len(valid_samples), "é—®é¢˜èƒŒæ™¯æ•…äº‹")
            success_count = 0
            for i, sample in enumerate(valid_samples):
                if i < len(parsed_stories) and not parsed_stories[i].startswith("Error"):
                    sample['narrative_story'] = parsed_stories[i]
                    sample['status'] = 'story_woven_with_relations'
                    
                    # åŒæ—¶ä¿å­˜å®ä½“æ³›åŒ–ä¿¡æ¯
                    sample['obfuscated_entities'] = self._extract_entity_obfuscation(
                        sample['integrated_clue_statement'], 
                        parsed_stories[i], 
                        sample.get('clue_entities', [])
                    )
                    success_count += 1
                else:
                    # å›é€€åˆ°æ•´åˆçš„çº¿ç´¢é™ˆè¿°ï¼Œä½†è¿›è¡Œç®€å•çš„æ³›åŒ–å¤„ç†
                    orig_statement = sample.get('integrated_clue_statement', 'ç›¸å…³å®ä½“é—´å­˜åœ¨æŸç§å…³è”')
                    target_entity = sample.get('target_entity', '')
                    # ç®€å•æ³›åŒ–å¤„ç†ï¼šæ›¿æ¢ç›®æ ‡å®ä½“ä¸º"æŸä¸ªå®ä½“"
                    if target_entity and target_entity in orig_statement:
                        simplified_story = orig_statement.replace(target_entity, "æŸä¸ªç›¸å…³å®ä½“")
                    else:
                        simplified_story = orig_statement
                    sample['narrative_story'] = simplified_story
                    sample['status'] = 'fallback_story'
            
            # å¤„ç†æ— æ•ˆæ ·æœ¬
            for sample in batch_samples:
                if sample not in valid_samples:
                    sample['narrative_story'] = sample.get('integrated_clue_statement', 'ç›¸å…³å®ä½“é—´å­˜åœ¨æŸç§å…³è”')
                    sample['status'] = 'invalid_input'
                    
            print(f"    æ¨¡ç³ŠåŒ–å¤„ç†å®Œæˆï¼š{success_count}/{len(batch_samples)} ä¸ªæ ·æœ¬")
        else:
            print(f"    æ¨¡ç³ŠåŒ–APIè°ƒç”¨å¤±è´¥: {results_str}")
            # å›é€€å¤„ç†ï¼šç®€å•æ³›åŒ–
            for sample in batch_samples:
                orig_statement = sample.get('integrated_clue_statement', 'ç›¸å…³å®ä½“é—´å­˜åœ¨æŸç§å…³è”')
                target_entity = sample.get('target_entity', '')
                # ç®€å•æ³›åŒ–å¤„ç†ï¼šæ›¿æ¢ç›®æ ‡å®ä½“ä¸º"æŸä¸ªå®ä½“"
                if target_entity and target_entity in orig_statement:
                    simplified_story = orig_statement.replace(target_entity, "æŸä¸ªç›¸å…³å®ä½“")
                else:
                    simplified_story = orig_statement
                sample['narrative_story'] = simplified_story
                sample['status'] = 'api_failed'

    def _extract_entity_obfuscation(self, original_statement, obfuscated_story, clue_entities):
        """
        ä»åŸå§‹é™ˆè¿°å’Œæ¨¡ç³ŠåŒ–æ•…äº‹ä¸­æå–å®ä½“æ³›åŒ–æ˜ å°„
        """
        obfuscated_entities = {}
        
        for entity in clue_entities:
            if entity in original_statement and entity not in obfuscated_story:
                # å®ä½“è¢«æˆåŠŸæ³›åŒ–ï¼Œå°è¯•æ‰¾åˆ°å¯¹åº”çš„æ³›åŒ–æè¿°
                generic_desc = self._generalize_entity(entity)
                obfuscated_entities[entity] = generic_desc
        
        return obfuscated_entities
    
    def _atomic_obfuscation_batch(self, batch_samples):
        """
        åŸå­åŒ–æ¨¡ç³Šï¼šå¯¹æ¯ä¸ªçº¿ç´¢å®ä½“è¿›è¡Œç‹¬ç«‹çš„ã€ä¸Šä¸‹æ–‡æ— å…³çš„æ¨¡ç³ŠåŒ–å¤„ç†
        å¢å¼ºç‰ˆæœ¬ï¼šåŒ…å«å…³ç³»ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç¡®ä¿ä¸æ³„éœ²å®ä½“åç§°
        """
        print(f"    æ‰§è¡ŒåŸå­åŒ–æ¨¡ç³Šå¤„ç†...")
        
        # æ”¶é›†æ‰€æœ‰éœ€è¦æ¨¡ç³ŠåŒ–çš„å®ä½“åŠå…¶å…³ç³»ä¸Šä¸‹æ–‡
        entities_with_context = []
        entity_to_samples = {}  # å®ä½“åˆ°æ ·æœ¬çš„æ˜ å°„
        
        for sample in batch_samples:
            clue_entities = sample.get('clue_entities', [])
            relation_facts = sample.get('relation_facts', [])
            
            for entity in clue_entities:
                if entity not in entity_to_samples:
                    entity_to_samples[entity] = []
                    
                    # ä¸ºå®ä½“æ”¶é›†å…³ç³»ä¸Šä¸‹æ–‡
                    entity_context = self._extract_entity_context(entity, relation_facts)
                    entities_with_context.append({
                        'entity': entity,
                        'context': entity_context
                    })
                
                entity_to_samples[entity].append(sample)
        
        if not entities_with_context:
            print(f"    âš ï¸  æ²¡æœ‰æ‰¾åˆ°éœ€è¦æ¨¡ç³ŠåŒ–çš„å®ä½“")
            return
        
        # æ‰¹é‡å¯¹å®ä½“è¿›è¡Œæ¨¡ç³ŠåŒ–ï¼ˆåŸºäºv4ç‰ˆæœ¬çš„ä¸¥æ ¼è¦æ±‚ï¼‰
        prompt = """ä½ æ˜¯ä¸€ä½ä¿¡æ¯æŠ½è±¡ä¸“å®¶ã€‚è¯·ä¸ºä»¥ä¸‹æ¯ä¸ªå®ä½“ç”Ÿæˆä¸€ä¸ªæ¨¡ç³Šä½†å…·æœ‰å”¯ä¸€æŒ‡å‘æ€§çš„æè¿°ã€‚

ä¸¥æ ¼è¦æ±‚ï¼š
1. **ç»å¯¹ç¦æ­¢æ³„éœ²**ï¼šæè¿°ä¸­ä¸èƒ½å‡ºç°è¯¥å®ä½“çš„å…·ä½“åç§°æˆ–ä»»ä½•ç›´æ¥æ ‡è¯†ç¬¦
2. **å”¯ä¸€æŒ‡å‘æ€§**ï¼šæè¿°è¦è¶³å¤Ÿå…·ä½“ï¼Œèƒ½å”¯ä¸€æŒ‡å‘è¯¥å®ä½“ï¼Œä½†åˆè¦ä¿æŒæ¨¡ç³Š
3. **å…³ç³»å¯¼å‘**ï¼šå……åˆ†åˆ©ç”¨æä¾›çš„å…³ç³»ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç¡®ä¿æè¿°å‡†ç¡®ä¸”æœ‰åŒºåˆ†åº¦
4. **æè¿°æ€§è¯­è¨€**ï¼šä½¿ç”¨é€šç”¨çš„ã€æè¿°æ€§çš„è¯­è¨€ï¼Œé¿å…ä¸“æœ‰åè¯
5. **é•¿åº¦æ§åˆ¶**ï¼šæ¯ä¸ªæè¿°æ§åˆ¶åœ¨15å­—ä»¥å†…

ç¤ºä¾‹å‚è€ƒï¼š
- é™ˆæ™“å¿ -> ä¸€ä½è‘—åçš„ç¾é£Ÿçºªå½•ç‰‡å¯¼æ¼”
- ä¸­å›½ä¼ åª’å¤§å­¦ -> ä¸€æ‰€ä»¥ä¿¡æ¯ä¼ æ’­é—»åçš„é«˜ç­‰å­¦åºœ
- æç«‹å® -> ä¸€ä½å£°éŸ³æµ‘åšçš„å›½å®¶çº§é…éŸ³æ¼”å‘˜

ç°åœ¨è¯·å¤„ç†ä»¥ä¸‹å®ä½“ï¼ˆåŒ…å«å…¶å…³ç³»ä¸Šä¸‹æ–‡ï¼‰ï¼š
"""
        
        for i, entity_info in enumerate(entities_with_context):
            entity = entity_info['entity']
            context = entity_info['context']
            
            prompt += f"\nå®ä½“ {i + 1}: {entity}\n"
            if context:
                prompt += f"   å…³ç³»ä¸Šä¸‹æ–‡: {'; '.join(context)}\n"
            else:
                prompt += f"   å…³ç³»ä¸Šä¸‹æ–‡: æ— ç›´æ¥å…³ç³»ä¿¡æ¯\n"
        
        prompt += "\n\nè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ï¼Œæ¯ä¸ªæè¿°å ä¸€è¡Œ:\næè¿° 1: [åŸºäºä¸Šä¸‹æ–‡çš„æ¨¡ç³ŠåŒ–æè¿°]\næè¿° 2: [åŸºäºä¸Šä¸‹æ–‡çš„æ¨¡ç³ŠåŒ–æè¿°]\n..."
        
        results_str = self._batch_llm_call(prompt)
        
        # è§£æç»“æœå¹¶åˆ†é…ç»™æ ·æœ¬
        obfuscated_descriptions = {}
        
        if results_str and not results_str.startswith("APIè°ƒç”¨å¤±è´¥"):
            parsed_descriptions = self._parse_llm_response(results_str, len(entities_with_context), "æè¿°")
            
            for i, description in enumerate(parsed_descriptions):
                if i < len(entities_with_context):
                    entity = entities_with_context[i]['entity']
                    # ä¸¥æ ¼æ£€æŸ¥æ˜¯å¦æ³„éœ²å®ä½“åç§°
                    if not self._contains_entity_leak(description, entity):
                        obfuscated_descriptions[entity] = description
                    else:
                        # å¦‚æœæ£€æµ‹åˆ°æ³„éœ²ï¼Œä½¿ç”¨æ›´å®‰å…¨çš„é€šç”¨æè¿°
                        obfuscated_descriptions[entity] = self._get_generic_entity_desc(entity)
        else:
            print(f"    âŒ LLMè°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å®‰å…¨çš„é€šç”¨æè¿°")
            for entity_info in entities_with_context:
                entity = entity_info['entity']
                obfuscated_descriptions[entity] = self._get_generic_entity_desc(entity)
        
        # å°†æ¨¡ç³ŠåŒ–ç»“æœåˆ†é…ç»™å„ä¸ªæ ·æœ¬
        for sample in batch_samples:
            sample_obfuscated = {}
            clue_entities = sample.get('clue_entities', [])
            
            for entity in clue_entities:
                if entity in obfuscated_descriptions:
                    sample_obfuscated[entity] = obfuscated_descriptions[entity]
            
            sample['obfuscated_entities'] = sample_obfuscated
        
        success_count = len([s for s in batch_samples if s.get('obfuscated_entities')])
        print(f"    åŸå­åŒ–æ¨¡ç³Šå®Œæˆï¼š{success_count}/{len(batch_samples)} ä¸ªæ ·æœ¬")

    def _extract_entity_context(self, entity, relation_facts):
        """
        ä¸ºå®ä½“æå–å…³ç³»ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Args:
            entity: ç›®æ ‡å®ä½“
            relation_facts: å…³ç³»äº‹å®åˆ—è¡¨
            
        Returns:
            list: ä¸è¯¥å®ä½“ç›¸å…³çš„å…³ç³»æè¿°
        """
        context = []
        
        for fact in relation_facts:
            if fact['subject'] == entity:
                context.append(f"{fact['relation']}{fact['object']}")
            elif fact['object'] == entity:
                context.append(f"è¢«{fact['subject']}{fact['relation']}")
        
        return context[:3]  # æœ€å¤šè¿”å›3ä¸ªå…³ç³»ä¸Šä¸‹æ–‡
    
    def _contains_entity_leak(self, description, entity):
        """
        æ£€æŸ¥æè¿°æ˜¯å¦æ³„éœ²äº†å®ä½“çš„çœŸå®åç§°
        
        Args:
            description: æ¨¡ç³ŠåŒ–æè¿°
            entity: åŸå§‹å®ä½“åç§°
            
        Returns:
            bool: å¦‚æœæ£€æµ‹åˆ°æ³„éœ²è¿”å›True
        """
        if not description or not entity:
            return False
        
        description_lower = description.lower()
        entity_lower = str(entity).lower()
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å®Œæ•´çš„å®ä½“åç§°
        if entity_lower in description_lower:
            return True
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å®ä½“åç§°çš„ä¸»è¦éƒ¨åˆ†ï¼ˆè¶…è¿‡2ä¸ªå­—ç¬¦ï¼‰
        if len(entity) > 2:
            for i in range(len(entity) - 2):
                substring = entity[i:i+3].lower()
                if substring in description_lower:
                    return True
        
        return False
    
    def _get_generic_entity_desc(self, entity):
        """
        ä¸ºå®ä½“ç”Ÿæˆæ›´è‡ªç„¶çš„é€šç”¨æè¿°ï¼Œé¿å…"æŸå®ä½“"è¿™æ ·æœºæ¢°çš„è¡¨è¿°
        
        Args:
            entity: å®ä½“åç§°
            
        Returns:
            str: è‡ªç„¶çš„é€šç”¨æè¿°
        """
        # ç®€å•çš„å®ä½“ç±»å‹åˆ¤æ–­è§„åˆ™
        if any(keyword in str(entity) for keyword in ['å…¬å¸', 'é›†å›¢', 'æœ‰é™', 'è‚¡ä»½', 'ç§‘æŠ€', 'å·¥ä¸š', 'å•†ä¸š']):
            return "ä¸€å®¶çŸ¥åä¼ä¸š"
        elif any(keyword in str(entity) for keyword in ['å¤§å­¦', 'å­¦é™¢', 'å­¦æ ¡', 'æ•™è‚²']):
            return "ä¸€æ‰€æ•™è‚²æœºæ„"
        elif any(keyword in str(entity) for keyword in ['åŒ»é™¢', 'è¯Šæ‰€', 'å«ç”Ÿ']):
            return "ä¸€ä¸ªåŒ»ç–—æœºæ„"
        elif any(keyword in str(entity) for keyword in ['é“¶è¡Œ', 'ä¿é™©', 'è¯åˆ¸', 'åŸºé‡‘', 'é‡‘è']):
            return "ä¸€ä¸ªé‡‘èæœºæ„"
        elif any(keyword in str(entity) for keyword in ['ç”µå½±', 'ç”µè§†å‰§', 'çºªå½•ç‰‡', 'åŠ¨ç”»']):
            return "ä¸€éƒ¨å½±è§†ä½œå“"
        elif any(keyword in str(entity) for keyword in ['æ­Œæ›²', 'ä¸“è¾‘', 'éŸ³ä¹']):
            return "ä¸€é¦–éŸ³ä¹ä½œå“"
        elif any(keyword in str(entity) for keyword in ['å°è¯´', 'æ•£æ–‡', 'è¯—æ­Œ', 'è‘—ä½œ', 'ä½œå“']):
            return "ä¸€éƒ¨æ–‡å­¦ä½œå“"
        elif len(str(entity)) <= 4 and not any(char.isdigit() for char in str(entity)):
            # çŸ­å­—ç¬¦ä¸²ä¸”æ— æ•°å­—ï¼Œå¯èƒ½æ˜¯äººå
            return "ä¸€ä½äººç‰©"
        elif any(keyword in str(entity) for keyword in ['å¸‚', 'çœ', 'å¿', 'åŒº', 'è¡—é“', 'è·¯']):
            return "ä¸€ä¸ªåœ°ç†ä½ç½®"
        elif any(keyword in str(entity) for keyword in ['å¹´', 'æœˆ', 'æ—¥', 'æ—¶æœŸ', 'æœä»£']):
            return "ä¸€ä¸ªæ—¶é—´ç‚¹"
        elif str(entity).isdigit() or any(char.isdigit() for char in str(entity)):
            return "ä¸€ä¸ªæ•°å€¼"
        else:
            # é»˜è®¤æƒ…å†µï¼Œå°è¯•æ ¹æ®å­—ç¬¦ç‰¹å¾åˆ¤æ–­
            if len(str(entity)) <= 6:
                return "ç›¸å…³å¯¹è±¡"
            else:
                return "ç›¸å…³å†…å®¹"
    
    def _narrative_weaving_batch(self, batch_samples):
        """
        æ•…äº‹ç¼–ç»‡ï¼šå°†æ¨¡ç³ŠåŒ–çš„æè¿°ç¼–ç»‡æˆè¿è´¯çš„æ‚¬ç–‘æ•…äº‹
        """
        print(f"    æ‰§è¡Œæ•…äº‹ç¼–ç»‡...")
        
        valid_samples = []
        for sample in batch_samples:
            if sample.get('obfuscated_entities'):
                valid_samples.append(sample)
        
        if not valid_samples:
            print(f"    âš ï¸  æ²¡æœ‰å¯ç”¨äºæ•…äº‹ç¼–ç»‡çš„æ ·æœ¬")
            return
        
        # ä¸ºæ¯ä¸ªæ ·æœ¬å•ç‹¬ç¼–ç»‡æ•…äº‹
        for sample in valid_samples:
            self._weave_single_narrative(sample)
        
        success_count = len([s for s in valid_samples if s.get('narrative_story')])
        print(f"    æ•…äº‹ç¼–ç»‡å®Œæˆï¼š{success_count}/{len(valid_samples)} ä¸ªæ ·æœ¬")
    
    def _weave_single_narrative(self, sample):
        """
        ä¸ºå•ä¸ªæ ·æœ¬ç¼–ç»‡æ•…äº‹ï¼ˆå¢å¼ºç‰ˆæœ¬ï¼šåŸºäºçœŸå®å…³ç³»è·¯å¾„ï¼‰
        """
        obfuscated_entities = sample.get('obfuscated_entities', {})
        answer_entity = sample.get('answer_entity', '')
        relation_facts = sample.get('relation_facts', [])
        
        if not obfuscated_entities:
            return
        
        # æ„å»ºåŸºäºå…³ç³»è·¯å¾„çš„æ•…äº‹ç¼–ç»‡prompt
        prompt = f"""ä½ æ˜¯ä¸€ä½é€»è¾‘ä¸¥è°¨çš„è°œé¢˜æ„å»ºä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä¸‹é¢æä¾›çš„ã€æ¨¡ç³Šå®ä½“æè¿°ã€‘å’Œã€å®ä½“é—´çš„çœŸå®å…³ç³»ã€‘ï¼Œå°†å®ƒä»¬æ•´åˆæˆä¸€æ®µå®¢è§‚çš„ä¿¡æ¯é™ˆè¿°ã€‚

è¯·éµå¾ªä»¥ä¸‹æ ¸å¿ƒå‡†åˆ™ï¼š
1. **åŸºäºäº‹å®å…³ç³»**ï¼šä¸¥æ ¼æŒ‰ç…§æä¾›çš„çœŸå®å…³ç³»æ¥æè¿°å®ä½“é—´çš„è”ç³»ï¼Œä¸è¦æœæ’°å…³ç³»ã€‚
2. **å®¢è§‚æ•´åˆ**ï¼šå°†æ¨¡ç³Šæè¿°å’Œå…³ç³»ä¿¡æ¯å®¢è§‚åœ°æ•´åˆï¼Œä¸“æ³¨äºäº‹å®å‘ˆç°ã€‚
3. **é€»è¾‘è¿è´¯**ï¼šç¡®ä¿æè¿°ç¬¦åˆæä¾›çš„å…³ç³»è·¯å¾„ï¼Œé€»è¾‘è¿è´¯ã€‚
4. **é¿å…æ–‡å­¦åŒ–**ï¼šä¿æŒä¸­ç«‹ã€ç®€æ´ã€ç›´æ¥çš„è¯­è¨€é£æ ¼ã€‚
5. **å®Œæ•´æ€§**ï¼šç¡®ä¿æ‰€æœ‰æ¨¡ç³Šæè¿°å’Œå…³ç³»éƒ½ä½“ç°åœ¨æœ€ç»ˆé™ˆè¿°ä¸­ã€‚

---
ã€æ¨¡ç³Šå®ä½“æè¿°ã€‘ï¼š
"""
        
        descriptions = list(obfuscated_entities.values())
        for i, desc in enumerate(descriptions):
            prompt += f"{i+1}. {desc}\n"
        
        # æ·»åŠ çœŸå®å…³ç³»ä¿¡æ¯
        prompt += f"\nã€å®ä½“é—´çš„çœŸå®å…³ç³»ã€‘ï¼š\n"
        if relation_facts:
            for i, fact in enumerate(relation_facts):
                # ä½¿ç”¨æ¨¡ç³Šæè¿°è€Œä¸æ˜¯çœŸå®å®ä½“åï¼Œå¦‚æœæ²¡æœ‰æ¨¡ç³Šæè¿°åˆ™ä½¿ç”¨æ™ºèƒ½åŒ–çš„é€šç”¨è¡¨è¿°
                subj_desc = obfuscated_entities.get(fact['subject'], self._get_generic_entity_desc(fact['subject']))
                obj_desc = obfuscated_entities.get(fact['object'], self._get_generic_entity_desc(fact['object']))
                prompt += f"{i+1}. {subj_desc} {fact['relation']} {obj_desc}\n"
        else:
            prompt += "æ— å…·ä½“å…³ç³»ä¿¡æ¯ï¼Œè¯·åŸºäºæè¿°è¿›è¡Œåˆç†å…³è”ã€‚\n"
        
        prompt += f"""
---

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ç”Ÿæˆä¸€æ®µå®¢è§‚çš„èƒŒæ™¯é™ˆè¿°ï¼Œè¦æ±‚ï¼š
- ä½“ç°æ‰€æœ‰æ¨¡ç³Šå®ä½“æè¿°
- ä¸¥æ ¼éµå¾ªæä¾›çš„å…³ç³»è·¯å¾„
- è¯­è¨€å®¢è§‚ã€ç®€æ´
- ä¸ºåç»­é—®é¢˜åšé“ºå«
- è¯­è¨€æµç•…ï¼Œä¸è¦å‡ºç°â€œæŸå®ä½“â€çš„è¡¨è¿°ï¼Œå¦‚æœå®ä½“æ˜¯äººï¼Œåˆ™ç”¨â€œæŸäººâ€ã€â€œè¯¥äººâ€ç­‰ä»£æ›¿ï¼Œå…¶ä»–ç±»å‹å®ä½“ä¹Ÿéœ€åŒæ ·æ ¹æ®å…¶æ€§è´¨è¡¨è¿°ã€‚

ç›´æ¥è¾“å‡ºé™ˆè¿°å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•å‰ç¼€æˆ–è¯´æ˜ã€‚"""
        
        result = self._batch_llm_call(prompt)
        
        if result and not result.startswith("APIè°ƒç”¨å¤±è´¥"):
            # æ£€æŸ¥ç”Ÿæˆçš„æ•…äº‹æ˜¯å¦æ³„éœ²ç­”æ¡ˆ
            if not self._contains_entity_leak(result, answer_entity):
                sample['narrative_story'] = result.strip()
                sample['status'] = 'story_woven_with_relations'
            else:
                # å¦‚æœæ³„éœ²ç­”æ¡ˆï¼Œä½¿ç”¨æ›´å®‰å…¨çš„å›é€€æ–¹æ¡ˆ
                safe_story = self._create_safe_fallback_story(descriptions, relation_facts)
                sample['narrative_story'] = safe_story
                sample['status'] = 'story_safe_fallback'
        else:
            # å›é€€åˆ°åŸºäºå…³ç³»çš„å®‰å…¨æ‹¼æ¥
            safe_story = self._create_safe_fallback_story(descriptions, relation_facts)
            sample['narrative_story'] = safe_story
            sample['status'] = 'story_fallback_with_relations'

    def _create_safe_fallback_story(self, descriptions, relation_facts):
        """
        åˆ›å»ºå®‰å…¨çš„å›é€€æ•…äº‹ï¼Œç¡®ä¿ä¸æ³„éœ²ç­”æ¡ˆ
        """
        if not descriptions:
            return "å­˜åœ¨ä¸€äº›ç›¸å…³çš„çº¿ç´¢å’Œå…³ç³»"
        
        if relation_facts and len(descriptions) > 1:
            return f"æ ¹æ®ç›¸å…³çº¿ç´¢ï¼Œ{descriptions[0]}é€šè¿‡{relation_facts[0]['relation']}ç­‰å…³ç³»ä¸{descriptions[1]}ç­‰å†…å®¹ç›¸äº’å…³è”ï¼Œè¿™äº›å…³ç³»çº¿ç´¢å…±åŒæŒ‡å‘ä¸€ä¸ªç‰¹å®šçš„ç›®æ ‡ã€‚"
        else:
            return f"æ ¹æ®ç›¸å…³çº¿ç´¢ï¼Œæ¶‰åŠ{', '.join(descriptions[:3])}ç­‰å†…å®¹ï¼Œè¿™äº›çº¿ç´¢å…±åŒæŒ‡å‘ä¸€ä¸ªç‰¹å®šçš„ç›®æ ‡ã€‚"

    def _question_generation_and_validation_batch(self, batch_samples):
        """
        ç¬¬ä¸‰é˜¶æ®µï¼šé—®é¢˜ç”Ÿæˆä¸æ ¡éªŒï¼ˆåŸºäºv4ç‰ˆæœ¬çš„é«˜çº§LLMåŒ…è£…é€»è¾‘ï¼‰
        
        è¿™ä¸ªé˜¶æ®µå°†ï¼š
        1. åŸºäºæ•…äº‹ç”Ÿæˆé—®é¢˜
        2. å¯¹ç”Ÿæˆçš„é—®é¢˜è¿›è¡Œç­”æ¡ˆé€»è¾‘æ ¡éªŒ
        3. ç¡®ä¿é—®é¢˜å¯ä»¥é€šè¿‡æ¨ç†å¾—åˆ°æ­£ç¡®ç­”æ¡ˆ
        """
        print(f"  å¼€å§‹é—®é¢˜ç”Ÿæˆä¸æ ¡éªŒ...")
        
        # ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆé—®é¢˜
        self._generate_questions_from_narrative_batch(batch_samples)
        
        # ç¬¬äºŒæ­¥ï¼šæ ¡éªŒé—®é¢˜
        self._validate_questions_batch(batch_samples)
        
        print(f"  é—®é¢˜ç”Ÿæˆä¸æ ¡éªŒå®Œæˆ")
    
    def _generate_questions_from_narrative_batch(self, batch_samples):
        """
        åŸºäºæ•…äº‹èƒŒæ™¯ç”Ÿæˆé—®é¢˜
        """
        print(f"    æ‰§è¡Œé—®é¢˜ç”Ÿæˆ...")
        
        valid_samples = []
        for sample in batch_samples:
            if sample.get('narrative_story') and sample.get('answer_entity'):
                valid_samples.append(sample)
        
        if not valid_samples:
            print(f"    âš ï¸  æ²¡æœ‰å¯ç”¨äºé—®é¢˜ç”Ÿæˆçš„æ ·æœ¬")
            return
        
        # ä¸ºæ¯ä¸ªæ ·æœ¬ç”Ÿæˆé—®é¢˜
        for sample in valid_samples:
            self._generate_single_question(sample)
        
        success_count = len([s for s in valid_samples if s.get('generated_question')])
        print(f"    é—®é¢˜ç”Ÿæˆå®Œæˆï¼š{success_count}/{len(valid_samples)} ä¸ªæ ·æœ¬")
    
    def _generate_single_question(self, sample):
        """
        ä¸ºå•ä¸ªæ ·æœ¬ç”Ÿæˆå®Œæ•´çš„é—®é¢˜ï¼ˆåŸºäºv4ç‰ˆæœ¬çš„ä¸¥æ ¼è¦æ±‚ï¼Œå‚è€ƒç›®æ ‡æ ¼å¼ï¼‰
        """
        narrative_story = sample.get('narrative_story', '')
        answer_entity = sample.get('answer_entity', '')
        clue_entities = sample.get('clue_entities', [])
        relation_facts = sample.get('relation_facts', [])
        
        prompt = f"""ä½ æ˜¯ä¸€ä½ç²¾å‡†çš„æé—®ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ä¸‹é¢æä¾›çš„ã€èƒŒæ™¯é™ˆè¿°ã€‘å’Œã€é¢„è®¾ç­”æ¡ˆã€‘ï¼Œåˆ›å»ºä¸€ä¸ªå®Œæ•´çš„é—®é¢˜ã€‚

æ ¸å¿ƒè¦æ±‚ï¼š
1. **ç­”æ¡ˆå¯¼å‘**ï¼šç”Ÿæˆçš„é—®é¢˜çš„å”¯ä¸€æ­£ç¡®ç­”æ¡ˆå¿…é¡»æ˜¯ç»™å®šçš„ã€é¢„è®¾ç­”æ¡ˆã€‘ã€‚
2. **è‡ªç„¶è¡”æ¥**ï¼šé—®é¢˜éœ€è¦ä¸ã€èƒŒæ™¯é™ˆè¿°ã€‘çš„ç»“å°¾ç´§å¯†è¡”æ¥ï¼Œè¯»èµ·æ¥é€šé¡ºè‡ªç„¶ã€‚
3. **ç»å¯¹ç¦æ­¢æ³„éœ²**ï¼šé—®é¢˜æœ¬èº«ä¸èƒ½åŒ…å«ã€é¢„è®¾ç­”æ¡ˆã€‘çš„ä»»ä½•ç›´æ¥çº¿ç´¢ã€æ–‡å­—æˆ–éƒ¨åˆ†å†…å®¹ã€‚
4. **ç®€æ´æ¸…æ™°**ï¼šé—®é¢˜è¡¨è¿°åº”ç®€æ´ã€æ¸…æ™°ï¼Œç¬¦åˆäººç±»çš„æé—®ä¹ æƒ¯ã€‚
5. **é€»è¾‘å®Œæ•´**ï¼šç¡®ä¿æ ¹æ®èƒŒæ™¯ä¿¡æ¯èƒ½å¤Ÿé€»è¾‘æ¨ç†å‡ºå”¯ä¸€ç­”æ¡ˆã€‚

è¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç”Ÿæˆå®Œæ•´é—®é¢˜ï¼š

**é—®é¢˜ï¼š**  
[åœ¨è¿™é‡Œå†™å…·ä½“çš„é—®é¢˜å†…å®¹ï¼Œä¸é—®é¢˜èƒŒæ™¯æ•…äº‹è‡ªç„¶è¡”æ¥]

**è§£æï¼š**  
1. [è§£æç¬¬ä¸€ä¸ªå…³é”®ä¿¡æ¯ç‚¹ï¼Œè¯´æ˜å¦‚ä½•ä»èƒŒæ™¯ä¸­è·å¾—çº¿ç´¢]
2. [è§£æç¬¬äºŒä¸ªå…³é”®ä¿¡æ¯ç‚¹ï¼Œè¯´æ˜æ¨ç†é€»è¾‘]
3. [æ€»ç»“æ¨ç†è¿‡ç¨‹ï¼Œè¯´æ˜å¦‚ä½•å¾—å‡ºæœ€ç»ˆç­”æ¡ˆ]

---
ã€èƒŒæ™¯é™ˆè¿°ã€‘ï¼š
{narrative_story}

ã€é¢„è®¾ç­”æ¡ˆã€‘ï¼š
{answer_entity}

ã€çº¿ç´¢å®ä½“ã€‘ï¼š
{', '.join(clue_entities)}
---

è¯·ä¸¥æ ¼æ ¹æ®ä»¥ä¸Šè¦æ±‚å’Œæ ¼å¼ï¼Œç”Ÿæˆå®Œæ•´çš„é—®é¢˜ï¼š"""

        result = self._batch_llm_call(prompt)
        
        if result and not result.startswith("APIè°ƒç”¨å¤±è´¥"):
            # æ£€æŸ¥é—®é¢˜æ˜¯å¦æ³„éœ²ç­”æ¡ˆ
            if not self._contains_entity_leak(result, answer_entity):
                sample['generated_question'] = result.strip()
                sample['answer'] = answer_entity
            else:
                # å¦‚æœæ³„éœ²ç­”æ¡ˆï¼Œç”Ÿæˆæ›´å®‰å…¨çš„é—®é¢˜
                safe_question = self._generate_safe_structured_question(narrative_story, answer_entity, clue_entities)
                sample['generated_question'] = safe_question
                sample['answer'] = answer_entity
        else:
            # å›é€€ï¼šç”Ÿæˆå®‰å…¨çš„ç»“æ„åŒ–é—®é¢˜
            safe_question = self._generate_safe_structured_question(narrative_story, answer_entity, clue_entities)
            sample['generated_question'] = safe_question
            sample['answer'] = answer_entity

    def _generate_safe_structured_question(self, narrative_story, answer_entity, clue_entities):
        """
        ç”Ÿæˆå®‰å…¨çš„ç»“æ„åŒ–é—®é¢˜ï¼Œç¡®ä¿ä¸æ³„éœ²ç­”æ¡ˆï¼ˆå‚è€ƒç›®æ ‡æ ¼å¼ï¼‰
        """
        if not narrative_story:
            narrative_story = "åœ¨æŸä¸ªå¤æ‚çš„å…³è”ç½‘ç»œä¸­ï¼Œå¤šä¸ªè¦ç´ ä¹‹é—´å­˜åœ¨ç€å¯†åˆ‡çš„è”ç³»ã€‚"
        
        # å®‰å…¨çš„é—®é¢˜æ¨¡æ¿
        question_templates = [
            "æ ¹æ®ä»¥ä¸Šæè¿°ï¼Œè¿™ä¸ªç½‘ç»œæœ€ç»ˆæŒ‡å‘çš„æ ¸å¿ƒæ¦‚å¿µæ˜¯ä»€ä¹ˆï¼Ÿ",
            "é€šè¿‡è¿™äº›å…³è”ä¿¡æ¯ï¼Œæœ€ç»ˆçš„ç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ", 
            "åŸºäºè¿™äº›çº¿ç´¢ï¼Œç­”æ¡ˆæ˜¯ä»€ä¹ˆï¼Ÿ",
            "è¿™ä¸ªå…³è”é“¾çš„ç»ˆç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ"
        ]
        
        main_question = random.choice(question_templates)
        
        # ç”Ÿæˆè§£æéƒ¨åˆ†
        analysis_parts = [
            f"1. æ•´åˆèƒŒæ™¯ä¿¡æ¯ä¸­çš„å¤šä¸ªå…³é”®è¦ç´ ï¼Œå‘ç°å®ƒä»¬å½¢æˆä¸€ä¸ªå…³è”ç½‘ç»œã€‚",
            f"2. é€šè¿‡åˆ†æ{len(clue_entities)}ä¸ªçº¿ç´¢å®ä½“ä¹‹é—´çš„é€»è¾‘å…³ç³»ï¼Œå»ºç«‹æ¨ç†é“¾æ¡ã€‚",
            f"3. ç»“åˆæ‰€æœ‰ä¿¡æ¯è¿›è¡Œç»¼åˆæ¨ç†ï¼Œç¡®å®šæœ€ç»ˆç­”æ¡ˆã€‚"
        ]
        
        # æ„å»ºå®Œæ•´çš„ç»“æ„åŒ–é—®é¢˜
        structured_question = f"""**é—®é¢˜ï¼š**  
{narrative_story}{main_question}  

**è§£æï¼š**  
{chr(10).join(analysis_parts)}"""
        
        return structured_question

    def _generate_safe_question(self, narrative_story):
        """
        ç”Ÿæˆå®‰å…¨çš„é€šç”¨é—®é¢˜ï¼Œç¡®ä¿ä¸æ³„éœ²ç­”æ¡ˆ
        """
        if not narrative_story:
            return "è¿™æ˜¯ä»€ä¹ˆï¼Ÿ"
        
        # åŸºäºæ•…äº‹å†…å®¹çš„å®‰å…¨é—®é¢˜æ¨¡æ¿
        safe_templates = [
            "è¿™æŒ‡å‘çš„æ˜¯ä»€ä¹ˆï¼Ÿ",
            "è¿™ä¸ªç›®æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ",
            "è¿™æè¿°çš„æ˜¯ä»€ä¹ˆï¼Ÿ",
            "æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œç­”æ¡ˆæ˜¯ä»€ä¹ˆï¼Ÿ"
        ]
        
        return random.choice(safe_templates)
    
    def _validate_questions_batch(self, batch_samples):
        """
        æ‰¹é‡æ ¡éªŒé—®é¢˜çš„é€»è¾‘æ­£ç¡®æ€§
        """
        print(f"    æ‰§è¡Œé—®é¢˜æ ¡éªŒ...")
        
        valid_samples = []
        for sample in batch_samples:
            if (sample.get('generated_question') and 
                sample.get('answer') and 
                sample.get('narrative_story')):
                valid_samples.append(sample)
        
        if not valid_samples:
            print(f"    âš ï¸  æ²¡æœ‰å¯ç”¨äºæ ¡éªŒçš„æ ·æœ¬")
            return
        
        # æ‰¹é‡æ ¡éªŒï¼ˆåŸºäºv4ç‰ˆæœ¬çš„ä¸¥æ ¼æ ‡å‡†ï¼‰
        validation_prompt = """ä½ æ˜¯ä¸€ä½é€»è¾‘æ¨ç†ä¸“å®¶ã€‚è¯·åˆ¤æ–­ä»¥ä¸‹æ¯ç»„ã€é—®é¢˜èƒŒæ™¯æ•…äº‹+é—®é¢˜ã€‘æ˜¯å¦èƒ½å¤Ÿé€»è¾‘æ¨ç†å‡ºå¯¹åº”çš„ã€ç­”æ¡ˆã€‘ã€‚

ä¸¥æ ¼è¯„åˆ¤æ ‡å‡†ï¼š
1. é—®é¢˜èƒŒæ™¯æ•…äº‹ä¸­çš„ä¿¡æ¯æ˜¯å¦è¶³å¤Ÿæ¨å¯¼å‡ºå”¯ä¸€ç­”æ¡ˆ
2. é—®é¢˜ä¸ç­”æ¡ˆæ˜¯å¦é€»è¾‘ä¸€è‡´
3. æ¨ç†é“¾æ¡æ˜¯å¦å®Œæ•´ä¸”æ— æ­§ä¹‰
4. é—®é¢˜æ˜¯å¦å­˜åœ¨ç­”æ¡ˆæ³„éœ²ï¼ˆåŒ…å«ç­”æ¡ˆçš„ç›´æ¥æˆ–é—´æ¥çº¿ç´¢ï¼‰

è¯·å¯¹æ¯ä¸ªé—®é¢˜ç»„åˆåªå›ç­”"é€šè¿‡"æˆ–"ä¸é€šè¿‡"ï¼š

"""
        
        for i, sample in enumerate(valid_samples):
            story = sample.get('narrative_story', '')
            question = sample.get('generated_question', '')
            answer = sample.get('answer', '')
            
            validation_prompt += f"""
é—®é¢˜ç»„åˆ {i + 1}:
é—®é¢˜èƒŒæ™¯æ•…äº‹ï¼š{story}
é—®é¢˜ï¼š{question}
ç­”æ¡ˆï¼š{answer}
"""
        
        validation_prompt += "\nè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ï¼Œæ¯ä¸ªç»“æœå ä¸€è¡Œ:\nç»“æœ 1: [é€šè¿‡/ä¸é€šè¿‡]\nç»“æœ 2: [é€šè¿‡/ä¸é€šè¿‡]\n..."
        
        validation_result = self._batch_llm_call(validation_prompt)
        
        # è§£ææ ¡éªŒç»“æœï¼ˆåŸºäºv4ç‰ˆæœ¬çš„ä¸¥æ ¼å¤„ç†ï¼‰
        if validation_result and not validation_result.startswith("APIè°ƒç”¨å¤±è´¥"):
            parsed_results = self._parse_llm_response(validation_result, len(valid_samples), "ç»“æœ")
            
            passed_count = 0
            for i, sample in enumerate(valid_samples):
                if i < len(parsed_results):
                    validation_status = parsed_results[i].lower()
                    sample['validation_status'] = "é€šè¿‡" if "é€šè¿‡" in validation_status else "ä¸é€šè¿‡"
                    
                    if "é€šè¿‡" in validation_status:
                        passed_count += 1
                        sample['final_status'] = 'validated'
                    else:
                        sample['final_status'] = 'validation_failed'
                else:
                    # é¢å¤–çš„æœ¬åœ°æ£€æŸ¥ï¼šç¡®ä¿é—®é¢˜ä¸åŒ…å«ç­”æ¡ˆ
                    question = sample.get('generated_question', '')
                    answer = sample.get('answer', '')
                    
                    if not self._contains_entity_leak(question, answer):
                        sample['validation_status'] = 'é€šè¿‡ï¼ˆæœ¬åœ°æ£€æŸ¥ï¼‰'
                        sample['final_status'] = 'validated'
                        passed_count += 1
                    else:
                        sample['validation_status'] = 'å¤±è´¥ï¼šé—®é¢˜æ³„éœ²ç­”æ¡ˆ'
                        sample['final_status'] = 'validation_failed'
            
            print(f"    æ ¡éªŒå®Œæˆï¼š{passed_count}/{len(valid_samples)} ä¸ªé—®é¢˜é€šè¿‡æ ¡éªŒ")
        else:
            print(f"    âš ï¸  LLMæ ¡éªŒå¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ£€æŸ¥")
            passed_count = 0
            for sample in valid_samples:
                question = sample.get('generated_question', '')
                answer = sample.get('answer', '')
                
                if not self._contains_entity_leak(question, answer):
                    sample['validation_status'] = 'é€šè¿‡ï¼ˆæœ¬åœ°æ£€æŸ¥ï¼‰'
                    sample['final_status'] = 'validated'
                    passed_count += 1
                else:
                    sample['validation_status'] = 'å¤±è´¥ï¼šé—®é¢˜æ³„éœ²ç­”æ¡ˆ'
                    sample['final_status'] = 'validation_failed'
            
            print(f"    æœ¬åœ°æ ¡éªŒå®Œæˆï¼š{passed_count}/{len(valid_samples)} ä¸ªé—®é¢˜é€šè¿‡")
        
        # ä¸ºä¸åœ¨valid_samplesä¸­çš„æ ·æœ¬è®¾ç½®é»˜è®¤çŠ¶æ€
        for sample in batch_samples:
            if sample not in valid_samples:
                sample['validation_status'] = 'å¤±è´¥ï¼šç¼ºå°‘å¿…è¦ä¿¡æ¯'
                sample['final_status'] = 'failed'
        
        validated_count = len([s for s in batch_samples if s.get('final_status') == 'validated'])
        print(f"    é—®é¢˜æ ¡éªŒå®Œæˆï¼š{validated_count}/{len(batch_samples)} é€šè¿‡")

    def _save_stage_results(self, batch_samples, stage_name, batch_idx):
        """ä¿å­˜é˜¶æ®µç»“æœ"""
        stage_dir = os.path.join(os.path.dirname(config.OUTPUT_DATASET_PATH), "stage_results")
        os.makedirs(stage_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        stage_file = os.path.join(stage_dir, f"{stage_name}_batch_{batch_idx:03d}_{timestamp}.jsonl")
        
        with open(stage_file, 'w', encoding='utf-8') as f:
            for sample in batch_samples:
                f.write(json.dumps(sample, ensure_ascii=False) + '\n')
        
        print(f"  é˜¶æ®µç»“æœå·²ä¿å­˜åˆ°: {stage_file}")
